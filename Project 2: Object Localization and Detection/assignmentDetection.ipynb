{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import patches\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.manual_seed(265)\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "path = 'datasets/'\n",
    "det_train_path = path + 'detection_train.pt'\n",
    "det_val_path = path + 'detection_val.pt'\n",
    "det_test_path = path + 'detection_test.pt'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 7  # Epochs\n",
    "BATCH_SIZE = 64  # Batch size\n",
    "KEEP_PROB = 1  # Dropout\n",
    "\n",
    "#Optimizer parameters\n",
    "LR = 1e-2  # Learning Rate\n",
    "BETAS = (0.9, 0.999)  # ADAM Momentum and RSMProp Betas\n",
    "EPSILON = 1e-8  # ADAM Vanishing and Exploding Gradients\n",
    "LAMBDA = 1e-4  # L2 Regularization\n",
    "\n",
    "models = []\n",
    "model_names = []\n",
    "loss_train_list = []\n",
    "loss_val_list = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/detection_train.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(det_train_path)\n\u001B[0;32m----> 2\u001B[0m detection_train_data \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdet_train_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m detection_val_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(det_val_path)\n\u001B[1;32m      4\u001B[0m detection_test_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(det_test_path)\n",
      "File \u001B[0;32m~/PycharmProjects/DeepLearning/venv/lib64/python3.10/site-packages/torch/serialization.py:777\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    772\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    773\u001B[0m     \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    774\u001B[0m     \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    775\u001B[0m     \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m    776\u001B[0m     orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m--> 777\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_zipfile_reader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_file\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[1;32m    778\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m _is_torchscript_zip(opened_zipfile):\n\u001B[1;32m    779\u001B[0m             warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorch.load\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m received a zip file that looks like a TorchScript archive\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    780\u001B[0m                           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m dispatching to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorch.jit.load\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (call \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorch.jit.load\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m directly to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    781\u001B[0m                           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m silence this warning)\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mUserWarning\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/DeepLearning/venv/lib64/python3.10/site-packages/torch/serialization.py:282\u001B[0m, in \u001B[0;36m_open_zipfile_reader.__init__\u001B[0;34m(self, name_or_buffer)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name_or_buffer) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 282\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_zipfile_reader, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPyTorchFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "print(det_train_path)\n",
    "detection_train_data = torch.load(det_train_path)\n",
    "detection_val_data = torch.load(det_val_path)\n",
    "detection_test_data = torch.load(det_test_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train normalization\n",
    "train_all = [x for x, _ in detection_train_data]\n",
    "train_to_one_tensor = torch.stack(train_all)\n",
    "\n",
    "mean_train = train_to_one_tensor.mean()\n",
    "std_train = train_to_one_tensor.std()\n",
    "\n",
    "detection_train_data.transform = transforms.Normalize(mean_train, std_train)\n",
    "\n",
    "\n",
    "# Val normalization\n",
    "val_all = [x for x, _ in detection_val_data]\n",
    "val_to_one_tensor = torch.stack(val_all)\n",
    "\n",
    "mean_val = val_to_one_tensor.mean()\n",
    "std_val = val_to_one_tensor.std()\n",
    "\n",
    "detection_val_data.transform = transforms.Normalize(mean_val, std_val)\n",
    "\n",
    "\n",
    "# Test normalization\n",
    "test_all = [x for x, _ in detection_test_data]\n",
    "test_to_one_tensor = torch.stack(test_all)\n",
    "\n",
    "mean_test = test_to_one_tensor.mean()\n",
    "std_test = test_to_one_tensor.std()\n",
    "\n",
    "detection_test_data.transform = transforms.Normalize(mean_test, std_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_random_img(data):\n",
    "    x, y = data.__getitem__(random.randint(0, len(data)))\n",
    "    # (C, H, W)\n",
    "    print(x.shape)\n",
    "    tensor_image = transforms.ToPILImage()(x).convert(\"RGB\")\n",
    "    plt.imshow(tensor_image)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_random_img(detection_train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Standard Convolutional LeNet5 Model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net01(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=120, out_channels=84, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=84, out_channels=7, kernel_size=(2, 4)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.layer2(y)\n",
    "        y = self.layer3(y)\n",
    "        y = self.layer4(y)\n",
    "        y = self.layer5(y)\n",
    "        y = y.permute(0, 2, 3, 1)\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shallow Convolutional LeNet5 Model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net02(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=84, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=84, out_channels=7, kernel_size=(4, 6)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.layer2(y)\n",
    "        y = self.layer3(y)\n",
    "        y = self.layer4(y)\n",
    "        y = y.permute(0, 2, 3, 1)\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Deep Convolutional LeNet5 Model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net03(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=12, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=240, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=240, out_channels=168, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=168, out_channels=84, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - KEEP_PROB)\n",
    "        )\n",
    "        self.layer6 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=84, out_channels=7, kernel_size=(2, 4)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.layer2(y)\n",
    "        y = self.layer3(y)\n",
    "        y = self.layer4(y)\n",
    "        y = self.layer5(y)\n",
    "        y = self.layer6(y)\n",
    "        y = y.permute(0, 2, 3, 1)\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Custom loss function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def myLoss(output, target):\n",
    "    # Uses BinaryClassification as a  loss function to train the network to recognize if there is a number in the cell or not\n",
    "    prob = output[:, :1]\n",
    "    probTarget = target[:, :1]\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_prob = loss_fn(prob, probTarget)\n",
    "\n",
    "    # Creates boolean mask based of if there is a number in the cell and filters out all labels where there is no number\n",
    "    outputShape = output.shape[1]\n",
    "    maskOutput = target[:, :1].eq(1).repeat(1, outputShape)\n",
    "    maskTarget = target[:, :1].eq(1).repeat(1, 6)\n",
    "    output = torch.masked_select(output, maskOutput)\n",
    "    target = torch.masked_select(target, maskTarget)\n",
    "    output = output.reshape(int(output.shape[0] / outputShape), outputShape)\n",
    "    target = target.reshape(int(target.shape[0] / 6), 6)\n",
    "\n",
    "    # If there is a number ni the cell it uses MeanSquaredError as a loss function to train the network to find the number's center and its bounding box\n",
    "    bb = output[:, 1:5]\n",
    "    bbTarget = target[:, 1:5].to(dtype=torch.double)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss_bb = loss_fn(bb, bbTarget)\n",
    "\n",
    "    # If there is a number in the cell it uses CrossEntropy as a loss function to train the network to classify the numbers\n",
    "    clas = output[:, 5:]\n",
    "    clasTarget = target[:, 5].to(dtype=torch.long)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_clas = loss_fn(clas, clasTarget)\n",
    "\n",
    "    return loss_prob + loss_bb + loss_clas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(n_epochs, optimizer, model, train_loader, train_mode):\n",
    "    \"\"\"\n",
    "    Train our model and save weight values\n",
    "    \"\"\"\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            # We use torch.double to get the same results as Pytorch\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = 0\n",
    "            for x in range(2):\n",
    "                for y in range(3):\n",
    "                    loss += myLoss(outputs[:, x, y, :], labels[:, x, y, :])\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        print('{}  |  Epoch {}  |  Training loss {:.5f}'.format(\n",
    "            datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    train_mode.append(losses_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(detection_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model01 = Net01().to(device=device)\n",
    "optimizer = optim.Adam(model01.parameters(), lr=LR, betas=BETAS, eps=EPSILON, weight_decay=LAMBDA)\n",
    "train(EPOCHS, optimizer, model01, train_loader, loss_train_list)\n",
    "models.append(model01)\n",
    "model_names.append(\"LeNet Standard\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(detection_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model02 = Net02().to(device=device)\n",
    "optimizer = optim.Adam(model02.parameters(), lr=LR, betas=BETAS, eps=EPSILON, weight_decay=LAMBDA)\n",
    "train(EPOCHS, optimizer, model02, train_loader, loss_train_list)\n",
    "models.append(model02)\n",
    "model_names.append(\"LeNet Shallow\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(detection_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model03 = Net03().to(device=device)\n",
    "optimizer = optim.Adam(model03.parameters(), lr=LR, betas=BETAS, eps=EPSILON, weight_decay=LAMBDA)\n",
    "train(EPOCHS, optimizer, model03, train_loader, loss_train_list)\n",
    "models.append(model03)\n",
    "model_names.append(\"LeNet Deep\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def intersection_over_union(pred_box: torch.tensor, label_box: torch.tensor):\n",
    "    # pred_box shape should be (N, 4), where N is the number of bboxs\n",
    "    # label_box shape is (N, 4)\n",
    "\n",
    "    box1_x1 = pred_box[..., 0:1] - pred_box[..., 2:3] / 2\n",
    "    box1_y1 = pred_box[..., 1:2] - pred_box[..., 3:4] / 2\n",
    "    box1_x2 = pred_box[..., 0:1] + pred_box[..., 2:3] / 2\n",
    "    box1_y2 = pred_box[..., 1:2] + pred_box[..., 3:4] / 2\n",
    "\n",
    "    box2_x1 = label_box[..., 0:1] - label_box[..., 2:3] / 2\n",
    "    box2_y1 = label_box[..., 1:2] - label_box[..., 3:4] / 2\n",
    "    box2_x2 = label_box[..., 0:1] + label_box[..., 2:3] / 2\n",
    "    box2_y2 = label_box[..., 1:2] + label_box[..., 3:4] / 2\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_highest_acc(output):\n",
    "    output = output.squeeze()\n",
    "    classes = [x.item() for x in output]\n",
    "    classes = classes[5:]\n",
    "    index = (classes.index(max(classes)))\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_vals(tensor: torch.tensor):\n",
    "    \"\"\"\n",
    "    :param tensor:\n",
    "    :return x, y, w, h:\n",
    "    \"\"\"\n",
    "    tens = tensor[1:5].clone().detach()\n",
    "    return torch.tensor(\n",
    "        [(int(tens[0] * 60)) - int((tens[2] / 2) * 60),\n",
    "         int(tens[1] * 48) - int((tens[3] / 2) * 48),\n",
    "         int(tens[2] * 60),\n",
    "         int(tens[3] * 48)],\n",
    "        dtype=torch.int)\n",
    "\n",
    "\n",
    "def compute_acc(model, loader):\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    IoU = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device)\n",
    "            output = model(imgs)\n",
    "            for x in range(2):\n",
    "                for y in range(3):\n",
    "                    tensor_ = output[:, x, y, :].squeeze()\n",
    "                    label_box = labels[:, x, y, :].squeeze()\n",
    "                    IoU += intersection_over_union(get_vals(label_box), get_vals(tensor_))\n",
    "                    tensor_[5:] = torch.nn.functional.softmax(tensor_[5:].clone(), dim=0)\n",
    "                    true_class = int(label_box[-1].item())\n",
    "                    predicted_class = find_highest_acc(tensor_)\n",
    "                    if true_class == predicted_class and label_box[0] > 0.67:\n",
    "                        correct += 1\n",
    "                        total += 1\n",
    "                    else:\n",
    "                        total += 1\n",
    "\n",
    "    return ((correct + IoU) / total).item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_model = len(models)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_model, figsize=(7 * n_model, 5), sharey=True, squeeze=False)\n",
    "\n",
    "for l_train, name, ax in zip(loss_train_list, model_names, axes.flat):\n",
    "    ax.plot(l_train, label='train', color=random.choice(['r', 'b', 'y', 'g', 'c', 'm']))\n",
    "    ax.set_title(str(name))\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_score = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    val_load = torch.utils.data.DataLoader(detection_val_data, shuffle=True)\n",
    "    model_perf = compute_acc(model, val_load) * 100\n",
    "    print(f\"Accuracy of model {model_names[i]} is {model_perf}\")\n",
    "    model_score.append(model_perf)\n",
    "\n",
    "index_best_model = (model_score.index(max(model_score)))\n",
    "best_model = models[index_best_model]\n",
    "print(f\"The best model is {model_names[index_best_model]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def draw_bounding_box_man(pan, true_tup, pred_tup, true_w, pred_w, true_h, pred_h):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(pan)\n",
    "    true_x = true_tup[0]\n",
    "    true_y = true_tup[1]\n",
    "    true_bb = patches.Rectangle((true_x, true_y), true_w, true_h, linewidth=3, edgecolor='r',\n",
    "                                facecolor='none')\n",
    "    pred_bb = patches.Rectangle((pred_tup[0], pred_tup[1]), pred_w, pred_h, linewidth=3, edgecolor='b',\n",
    "                                facecolor='none')\n",
    "\n",
    "    ax.add_patch(true_bb)\n",
    "    ax.add_patch(pred_bb)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img, label = detection_test_data[random.randint(0, len(detection_val_data))]\n",
    "img = img.to(device, dtype=torch.double)\n",
    "\n",
    "tensor_image = transforms.ToPILImage()(img).convert(\"RGB\")\n",
    "#plt.imshow(tensor_image)\n",
    "plt.show()\n",
    "\n",
    "# feed image to model\n",
    "model03.eval()\n",
    "output = model03(img.unsqueeze(0))\n",
    "\n",
    "for cel_x in range(2):\n",
    "    for cel_y in range(3):\n",
    "        tensor_ = output[:, cel_x, cel_y, :].squeeze()\n",
    "        label_box = label[cel_x, cel_y, :].squeeze()\n",
    "        print(label_box[0])\n",
    "        true_bbox = torch.tensor(\n",
    "            [(int(label_box[1] * 20) * cel_x) - int((label_box[3] / 2) * 20 * cel_x),\n",
    "             int(label_box[2] * 24 * cel_y) - int((label_box[4] / 2) * 24 * cel_y),\n",
    "             int(label_box[3] * 20),\n",
    "             int(label_box[4] * 24)],\n",
    "            dtype=torch.float)\n",
    "\n",
    "        pred_box = torch.tensor(\n",
    "            [(int(tensor_[1] * 24 * cel_y)) - int((tensor_[3] / 2) * 24 * cel_y),\n",
    "             int(tensor_[2] * 20 * cel_x) - int((tensor_[4] / 2) * 20 * cel_x),\n",
    "             int(tensor_[3] * 24),\n",
    "             int(tensor_[4] * 20)],\n",
    "            dtype=torch.float)\n",
    "\n",
    "\n",
    "        draw_bounding_box_man(tensor_image,\n",
    "                              (true_bbox[0], true_bbox[1]),\n",
    "                              (pred_box[0], pred_box[1]),\n",
    "                              true_bbox[2], pred_box[2],\n",
    "                              true_bbox[3], pred_box[3])\n",
    "        if tensor_[-1].item() > tensor_[-1].item():\n",
    "            print(\"Predicted label is 1\")\n",
    "        else:\n",
    "            print(\"Predicted label is 0\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the \"best\" found model test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Accuracy of model - based on test set\n",
    "test_load = torch.utils.data.DataLoader(detection_test_data, shuffle=True)\n",
    "model_perf = compute_acc(best_model, test_load) * 100\n",
    "print(f\"Accuracy of model was: {model_perf}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
