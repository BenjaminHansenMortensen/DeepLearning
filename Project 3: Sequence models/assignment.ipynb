{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7fad68489150>"
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from os import listdir\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data import get_tokenizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "torch.manual_seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 16\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 10  # Epochs\n",
    "BATCH_SIZE = 64  # Batch size  // Not used yet\n",
    "\n",
    "#Optimizer parameters\n",
    "LR = 1e-3  # Learning Rate\n",
    "BETAS = (0.9, 0.999)  # ADAM Momentum and RSMProp Betas\n",
    "EPSILON = 1e-8  # ADAM Vanishing and Exploding Gradients\n",
    "LAMBDA = 1e-8  # L2 Regularization\n",
    "\n",
    "\n",
    "SHALLOW_HIDDEN_SIZE = 32\n",
    "MIDDLE_HIDDEN_SIZE = 48\n",
    "DEEP_HIDDEN_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset: 1368807\n",
      "Number of distinct words in the training dataset: 30374\n",
      "Number of distinct words kept in the training dataset: 1050\n"
     ]
    }
   ],
   "source": [
    "# From Week14 Solutions\n",
    "\n",
    "# tokenizer will split a long text into a list of english words\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def read_files(datapath='../dataset/data_train'):\n",
    "    \"\"\"\n",
    "    Return a list of strings, one for each line in each .txt files in 'datapath'\n",
    "    \"\"\"\n",
    "    # Find all txt files in directory\n",
    "    files = listdir(datapath)\n",
    "    files = [datapath + \"/\" + f for f in files if f.endswith(\".txt\")]\n",
    "\n",
    "    # Stores each line of each book in a list\n",
    "    lines = []\n",
    "    for f_name in files:\n",
    "        with open(f_name) as f:\n",
    "            lines += f.readlines()\n",
    "    return lines\n",
    "\n",
    "books_train = read_files()\n",
    "books_val = read_files('../dataset/data_val')\n",
    "books_test = read_files('../dataset/data_test')\n",
    "\n",
    "# Match any word containing digit\n",
    "no_digits = '\\w*[0-9]+\\w*'\n",
    "# Match word containing a uppercase\n",
    "no_names = '\\w*[A-Z]+\\w*'\n",
    "# Match any sequence containing more than one space\n",
    "no_spaces = '\\s+'\n",
    "\n",
    "def tokenize(lines):\n",
    "    \"\"\"\n",
    "    Tokenize the list of lines\n",
    "    \"\"\"\n",
    "    list_text = []\n",
    "    for line in lines:\n",
    "        list_text += tokenizer(line)\n",
    "    return list_text\n",
    "\n",
    "def yield_tokens(lines):\n",
    "    \"\"\"\n",
    "    Yield tokens, ignoring names and digits to build vocabulary\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        line = re.sub(no_digits + \"|\" + no_names, ' ', line)\n",
    "        line = re.sub(no_spaces, ' ', line)\n",
    "        yield tokenizer(line)\n",
    "\n",
    "def count_freqs(data, vocab):\n",
    "    \"\"\"\n",
    "    Count occurrences of each word in vocabulary in the data\n",
    "    \"\"\"\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in data:\n",
    "        freqs[vocab[w]] += 1\n",
    "    return freqs\n",
    "\n",
    "# List of words contained in the dataset\n",
    "list_words_train = tokenize(books_train)\n",
    "list_words_val = tokenize(books_val)\n",
    "list_words_test = tokenize(books_test)\n",
    "\n",
    "# vocab contains the vocabulary found in the data, associating an index to each word\n",
    "vocab = build_vocab_from_iterator(yield_tokens(books_train), min_freq=100, specials=[\"<unk>\"])\n",
    "\n",
    "# Since we removed all words with an uppercase when building the vocabulary, we skipped the word \"I\"\n",
    "vocab.append_token(\"i\")\n",
    "\n",
    "# Value of default index. This index will be returned when OOV (Out Of Vocabulary) token is queried.\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "print(\"Total number of words in the training dataset:\", len(list_words_train))\n",
    "print(\"Number of distinct words in the training dataset:\", len(set(list_words_train)))\n",
    "print(\"Number of distinct words kept in the training dataset:\", vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "index2word = {}\n",
    "\n",
    "for i in range(len(vocab)):\n",
    "    index2word[i] = vocab.lookup_token(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [],
   "source": [
    "# From Week14 solutions\n",
    "\n",
    "def create_dataset(\n",
    "    text, vocab, context_size=CONTEXT_SIZE,\n",
    "):\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    n_text = len(text)\n",
    "\n",
    "    # Transform the text as a list of integers.\n",
    "    txt = [vocab[w] for w in text]\n",
    "\n",
    "    for i in range(n_text - context_size):\n",
    "\n",
    "        # true label = 'is the next word a known word (i.e. not '<unk>' token)?'\n",
    "        if txt[i + context_size] == 0:\n",
    "            continue\n",
    "\n",
    "        t = txt[i+context_size]\n",
    "\n",
    "        # Context before\n",
    "        c = txt[i:i + context_size]\n",
    "\n",
    "        targets.append(t)\n",
    "        # Normally we should use word embedding, and not hot encoding, but we\n",
    "        # skip that part for this exercise\n",
    "        contexts.append(torch.tensor(c))\n",
    "\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    return TensorDataset(contexts, targets)\n",
    "\n",
    "# data_train = create_dataset(list_words_train, vocab)\n",
    "# data_val = create_dataset(list_words_val, vocab)\n",
    "# data_test = create_dataset(list_words_test, vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [],
   "source": [
    "train_loader = torch.load('../saved_sets/train.pkl')\n",
    "val_loader = torch.load('../saved_sets/val.pkl')\n",
    "test_loader = torch.load('../saved_sets/test.pkl')\n",
    "# train_loader = DataLoader(data_train, batch_size=64, shuffle=False)\n",
    "# val_loader = DataLoader(data_val, batch_size=64, shuffle=False)\n",
    "# test_loader = DataLoader(data_test, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [],
   "source": [
    "# torch.save(train_loader, '../saved_sets/train.pkl')\n",
    "# torch.save(val_loader, '../saved_sets/val.pkl')\n",
    "# torch.save(test_loader, '../saved_sets/test.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "def train(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    \"\"\"\n",
    "    Train our model and save weight values\n",
    "    \"\"\"\n",
    "    n_batch = len(train_loader)\n",
    "    model.train()\n",
    "    losses_train = []\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        loss_train = 0.0\n",
    "        for contexts, labels in train_loader:\n",
    "\n",
    "            # We use torch.double to get the same results as Pytorch\n",
    "            #contexts = torch.permute(contexts, (1,0,2))\n",
    "            contexts = contexts.to(device=device, dtype=torch.long)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(contexts).squeeze()\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        print('{}  |  Epoch {}  |  Training loss {:.5f}'.format(\n",
    "            datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    return losses_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "class NGramModel1(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_size):\n",
    "        super(NGramModel1, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        embeds = torch.flatten(embeds, 1)\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear4(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "class NGramModel2(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_size):\n",
    "        super(NGramModel2, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        embeds = torch.flatten(embeds, 1)\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear4(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "class NGramModel3(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_size):\n",
    "        super(NGramModel3, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        embeds = torch.flatten(embeds, 1)\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear4(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "models, model_names, losses = [], [], []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:39:13.969373  |  Epoch 1  |  Training loss 4.37023\n",
      "16:40:05.712742  |  Epoch 2  |  Training loss 4.07252\n",
      "16:41:03.217113  |  Epoch 3  |  Training loss 4.02626\n",
      "16:42:08.325081  |  Epoch 4  |  Training loss 4.00679\n",
      "16:43:09.693991  |  Epoch 5  |  Training loss 3.99610\n",
      "16:44:10.640911  |  Epoch 6  |  Training loss 3.98999\n",
      "16:45:16.294798  |  Epoch 7  |  Training loss 3.98666\n",
      "16:46:01.873991  |  Epoch 8  |  Training loss 3.98417\n",
      "16:46:46.518388  |  Epoch 9  |  Training loss 3.98282\n",
      "16:47:31.233802  |  Epoch 10  |  Training loss 3.98184\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model1 = NGramModel1(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE, DEEP_HIDDEN_SIZE)\n",
    "optimizer = optim.RAdam(model1.parameters(), lr=LR, betas=BETAS, eps=EPSILON, weight_decay=LAMBDA)\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model1,\n",
    "    loss_function,\n",
    "    train_loader\n",
    ")\n",
    "\n",
    "models.append(model1)\n",
    "model_names.append(\"DEEP MODEL\")\n",
    "losses.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:47:57.972231  |  Epoch 1  |  Training loss 6.98147\n",
      "16:48:23.310689  |  Epoch 2  |  Training loss 6.98147\n",
      "16:48:48.806101  |  Epoch 3  |  Training loss 6.98147\n",
      "16:49:14.252102  |  Epoch 4  |  Training loss 6.98147\n",
      "16:49:39.617085  |  Epoch 5  |  Training loss 6.98147\n",
      "16:50:04.943064  |  Epoch 6  |  Training loss 6.98147\n",
      "16:50:30.265901  |  Epoch 7  |  Training loss 6.98147\n",
      "16:50:54.157038  |  Epoch 8  |  Training loss 6.98147\n",
      "16:51:23.251452  |  Epoch 9  |  Training loss 6.98147\n",
      "16:51:52.294504  |  Epoch 10  |  Training loss 6.98147\n"
     ]
    }
   ],
   "source": [
    "model2 = NGramModel2(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE, MIDDLE_HIDDEN_SIZE)\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model2,\n",
    "    loss_function,\n",
    "    train_loader\n",
    ")\n",
    "\n",
    "models.append(model2)\n",
    "model_names.append(\"MIDDLE MODEL\")\n",
    "losses.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:52:18.703200  |  Epoch 1  |  Training loss 7.01888\n",
      "16:52:43.020917  |  Epoch 2  |  Training loss 7.01888\n",
      "16:53:07.170012  |  Epoch 3  |  Training loss 7.01888\n",
      "16:53:31.254519  |  Epoch 4  |  Training loss 7.01888\n",
      "16:53:58.097034  |  Epoch 5  |  Training loss 7.01888\n",
      "16:54:23.601251  |  Epoch 6  |  Training loss 7.01888\n",
      "16:54:49.669688  |  Epoch 7  |  Training loss 7.01888\n",
      "16:55:15.218048  |  Epoch 8  |  Training loss 7.01888\n",
      "16:55:51.073203  |  Epoch 9  |  Training loss 7.01888\n",
      "16:56:35.102713  |  Epoch 10  |  Training loss 7.01888\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model3 = NGramModel3(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE, MIDDLE_HIDDEN_SIZE)\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model3,\n",
    "    loss_function,\n",
    "    train_loader\n",
    ")\n",
    "\n",
    "models.append(model3)\n",
    "model_names.append(\"SHALLOW MODEL\")\n",
    "losses.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, e in zip(losses, model_names):\n",
    "    plt.plot(i, label=e)\n",
    "    plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "def compute_accuracy(model, loader):\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    with torch.no_grad():\n",
    "        for contexts, labels in loader:\n",
    "            contexts = contexts.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(contexts)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += BATCH_SIZE\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "    acc =  correct / total\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "def find_best_model(loader):\n",
    "    max_accuracy = 0\n",
    "    best_model = 0\n",
    "    for i in range(len(models)):\n",
    "        model_accuracy = round(compute_accuracy(models[i], loader) * 100)\n",
    "\n",
    "        if model_accuracy > max_accuracy:\n",
    "            max_accuracy = model_accuracy\n",
    "            best_model = i\n",
    "\n",
    "    print(\"Best model is:\", model_names[best_model])\n",
    "\n",
    "    return models[best_model]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is: DEEP MODEL\n"
     ]
    }
   ],
   "source": [
    "best_model = find_best_model(val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of the best model is 18.1%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy of the best model is \" + str(round(compute_accuracy(best_model, test_loader) * 100, 2)) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'in' is similar to 'into'\n",
      "'he' is similar to 'she'\n",
      "'was' is similar to 'is'\n",
      "'was' is similar to 'been'\n",
      "'had' is similar to 'have'\n",
      "'had' is similar to 'has'\n",
      "'had' is similar to 'having'\n",
      "'him' is similar to 'me'\n",
      "'is' is similar to 'was'\n",
      "'is' is similar to 're'\n",
      "'!' is similar to '?'\n",
      "'?' is similar to '!'\n",
      "'she' is similar to 'he'\n",
      "'she' is similar to 'everyone'\n",
      "'said' is similar to 'cried'\n",
      "'said' is similar to 'answered'\n",
      "'have' is similar to 'had'\n",
      "'have' is similar to 'has'\n",
      "'have' is similar to 'having'\n",
      "'from' is similar to 'during'\n",
      "'me' is similar to 'him'\n",
      "'me' is similar to 'mine'\n",
      "'by' is similar to 'beyond'\n",
      "'were' is similar to 're'\n",
      "'my' is similar to 'your'\n",
      "'up' is similar to 'near'\n",
      "'up' is similar to 'rose'\n",
      "'would' is similar to 'will'\n",
      "'would' is similar to 'must'\n",
      "'would' is similar to 'should'\n",
      "'would' is similar to 'shall'\n",
      "'would' is similar to 'may'\n",
      "'would' is similar to 'might'\n",
      "'been' is similar to 'was'\n",
      "'been' is similar to 'being'\n",
      "'will' is similar to 'would'\n",
      "'will' is similar to 'must'\n",
      "'will' is similar to 'should'\n",
      "'will' is similar to 'shall'\n",
      "'will' is similar to 'may'\n",
      "'will' is similar to 'might'\n",
      "'could' is similar to 'can'\n",
      "'man' is similar to 'woman'\n",
      "'man' is similar to 'husband'\n",
      "'man' is similar to 'girl'\n",
      "'man' is similar to 'anyone'\n",
      "'man' is similar to 'someone'\n",
      "'man' is similar to 'gentleman'\n",
      "'did' is similar to 'does'\n",
      "'into' is similar to 'in'\n",
      "'into' is similar to 'through'\n",
      "'into' is similar to 'beyond'\n",
      "'do' is similar to 'does'\n",
      "'your' is similar to 'my'\n",
      "'time' is similar to 'ready'\n",
      "'time' is similar to 'reply'\n",
      "'went' is similar to 'rode'\n",
      "'came' is similar to 'rushed'\n",
      "'see' is similar to 'imagine'\n",
      "'down' is similar to 'move'\n",
      "'down' is similar to 'enter'\n",
      "'has' is similar to 'had'\n",
      "'has' is similar to 'have'\n",
      "'has' is similar to 'having'\n",
      "'know' is similar to 'knew'\n",
      "'know' is similar to 'understood'\n",
      "'himself' is similar to 'soldier'\n",
      "'can' is similar to 'could'\n",
      "'must' is similar to 'would'\n",
      "'must' is similar to 'will'\n",
      "'must' is similar to 'should'\n",
      "'must' is similar to 'shall'\n",
      "'must' is similar to 'may'\n",
      "'must' is similar to 'might'\n",
      "'over' is similar to 'near'\n",
      "'go' is similar to 'come'\n",
      "'go' is similar to 'going'\n",
      "'go' is similar to 'gone'\n",
      "'old' is similar to 'young'\n",
      "'face' is similar to 'head'\n",
      "'face' is similar to 'hair'\n",
      "'face' is similar to 'carefully'\n",
      "'how' is similar to 'why'\n",
      "'should' is similar to 'would'\n",
      "'should' is similar to 'will'\n",
      "'should' is similar to 'must'\n",
      "'should' is similar to 'shall'\n",
      "'should' is similar to 'may'\n",
      "'should' is similar to 'might'\n",
      "'come' is similar to 'go'\n",
      "'come' is similar to 'going'\n",
      "'two' is similar to 'three'\n",
      "'two' is similar to 'four'\n",
      "'two' is similar to 'hundred'\n",
      "'two' is similar to 'ten'\n",
      "'where' is similar to 'whom'\n",
      "'made' is similar to 'make'\n",
      "'made' is similar to 'making'\n",
      "'shall' is similar to 'would'\n",
      "'shall' is similar to 'will'\n",
      "'shall' is similar to 'must'\n",
      "'shall' is similar to 'should'\n",
      "'shall' is similar to 'may'\n",
      "'men' is similar to 'people'\n",
      "'men' is similar to 'soldiers'\n",
      "'men' is similar to 'generals'\n",
      "'good' is similar to 'special'\n",
      "'say' is similar to 'saying'\n",
      "'looked' is similar to 'looking'\n",
      "'looked' is similar to 'glanced'\n",
      "'looked' is similar to 'glance'\n",
      "'looked' is similar to 'gazed'\n",
      "'day' is similar to 'letters'\n",
      "'still' is similar to 'yet'\n",
      "'hand' is similar to 'window'\n",
      "'hand' is similar to 'arms'\n",
      "'hand' is similar to 'mouth'\n",
      "'hand' is similar to 'rapidly'\n",
      "'hand' is similar to 'river'\n",
      "'saw' is similar to 'noticed'\n",
      "'seemed' is similar to 'seem'\n",
      "'took' is similar to 'take'\n",
      "'took' is similar to 'taking'\n",
      "'own' is similar to 'real'\n",
      "'may' is similar to 'would'\n",
      "'may' is similar to 'will'\n",
      "'may' is similar to 'must'\n",
      "'may' is similar to 'should'\n",
      "'may' is similar to 'shall'\n",
      "'may' is similar to 'might'\n",
      "'head' is similar to 'face'\n",
      "'head' is similar to 'hands'\n",
      "'head' is similar to 'hair'\n",
      "'head' is similar to 'figure'\n",
      "'head' is similar to 'slowly'\n",
      "'head' is similar to 'carefully'\n",
      "'began' is similar to 'try'\n",
      "'began' is similar to 'begin'\n",
      "'door' is similar to 'road'\n",
      "'door' is similar to 'shoulders'\n",
      "'door' is similar to 'move'\n",
      "'here' is similar to 'tomorrow'\n",
      "'these' is similar to 'many'\n",
      "'think' is similar to 'hope'\n",
      "'through' is similar to 'into'\n",
      "'through' is similar to 'beyond'\n",
      "'being' is similar to 'been'\n",
      "'house' is similar to 'place'\n",
      "'house' is similar to 'spot'\n",
      "'house' is similar to 'cap'\n",
      "'take' is similar to 'took'\n",
      "'take' is similar to 'taking'\n",
      "'look' is similar to 'act'\n",
      "'might' is similar to 'would'\n",
      "'might' is similar to 'will'\n",
      "'might' is similar to 'must'\n",
      "'might' is similar to 'should'\n",
      "'might' is similar to 'may'\n",
      "'young' is similar to 'old'\n",
      "'young' is similar to 'poor'\n",
      "'make' is similar to 'made'\n",
      "'make' is similar to 'making'\n",
      "'tell' is similar to 'show'\n",
      "'knew' is similar to 'know'\n",
      "'knew' is similar to 'hear'\n",
      "'people' is similar to 'men'\n",
      "'people' is similar to 'children'\n",
      "'people' is similar to 'women'\n",
      "'people' is similar to 'officers'\n",
      "'yet' is similar to 'still'\n",
      "'put' is similar to 'keep'\n",
      "'put' is similar to 'laid'\n",
      "'put' is similar to 'threw'\n",
      "'father' is similar to 'wife'\n",
      "'father' is similar to 'husband'\n",
      "'father' is similar to 'lady'\n",
      "'father' is similar to 'tea'\n",
      "'turned' is similar to 'pointed'\n",
      "'gave' is similar to 'give'\n",
      "'gave' is similar to 'giving'\n",
      "'wife' is similar to 'father'\n",
      "'wife' is similar to 'son'\n",
      "'wife' is similar to 'husband'\n",
      "'wife' is similar to 'officer'\n",
      "'wife' is similar to 'lady'\n",
      "'wife' is similar to 'boy'\n",
      "'wife' is similar to 'character'\n",
      "'having' is similar to 'had'\n",
      "'having' is similar to 'have'\n",
      "'having' is similar to 'has'\n",
      "'having' is similar to 've'\n",
      "'place' is similar to 'house'\n",
      "'place' is similar to 'spot'\n",
      "'give' is similar to 'gave'\n",
      "'give' is similar to 'bring'\n",
      "'give' is similar to 'giving'\n",
      "'going' is similar to 'go'\n",
      "'going' is similar to 'come'\n",
      "'going' is similar to 'gone'\n",
      "'got' is similar to 'brought'\n",
      "'got' is similar to 'led'\n",
      "'whom' is similar to 'where'\n",
      "'woman' is similar to 'man'\n",
      "'woman' is similar to 'husband'\n",
      "'woman' is similar to 'lady'\n",
      "'woman' is similar to 'gentleman'\n",
      "'army' is similar to 'word'\n",
      "'army' is similar to 'events'\n",
      "'army' is similar to 'rooms'\n",
      "'army' is similar to 'condition'\n",
      "'morning' is similar to 'sky'\n",
      "'sat' is similar to 'lay'\n",
      "'three' is similar to 'two'\n",
      "'three' is similar to 'four'\n",
      "'three' is similar to 'several'\n",
      "'three' is similar to 'hundred'\n",
      "'three' is similar to 'ten'\n",
      "'voice' is similar to 'voices'\n",
      "'voice' is similar to 'generals'\n",
      "'looking' is similar to 'looked'\n",
      "'looking' is similar to 'glanced'\n",
      "'looking' is similar to 'running'\n",
      "'looking' is similar to 'gazed'\n",
      "'find' is similar to 'beside'\n",
      "'stood' is similar to 'standing'\n",
      "'words' is similar to 'events'\n",
      "'behind' is similar to 'kissed'\n",
      "'behind' is similar to 'interrupted'\n",
      "'hands' is similar to 'head'\n",
      "'hands' is similar to 'shoulders'\n",
      "'hands' is similar to 'slowly'\n",
      "'cried' is similar to 'said'\n",
      "'cried' is similar to 'replied'\n",
      "'answered' is similar to 'said'\n",
      "'answered' is similar to 'added'\n",
      "'many' is similar to 'these'\n",
      "'others' is similar to 'horses'\n",
      "'others' is similar to 'body'\n",
      "'others' is similar to 'police'\n",
      "'others' is similar to 'windows'\n",
      "'others' is similar to 'guns'\n",
      "'home' is similar to 'count'\n",
      "'alone' is similar to 'truth'\n",
      "'few' is similar to 'ten'\n",
      "'ran' is similar to 'rode'\n",
      "'ran' is similar to 'straight'\n",
      "'ran' is similar to 'walked'\n",
      "'ran' is similar to 'rushed'\n",
      "'ran' is similar to 'farther'\n",
      "'ran' is similar to 'galloped'\n",
      "'set' is similar to 'carried'\n",
      "'brought' is similar to 'got'\n",
      "'brought' is similar to 'led'\n",
      "'why' is similar to 'how'\n",
      "'ever' is similar to 'certainly'\n",
      "'smile' is similar to 'expression'\n",
      "'general' is similar to 'true'\n",
      "'general' is similar to 'enemy'\n",
      "'general' is similar to 'passion'\n",
      "'work' is similar to 'story'\n",
      "'work' is similar to 'box'\n",
      "'work' is similar to 'servants'\n",
      "'work' is similar to 'difficulty'\n",
      "'replied' is similar to 'cried'\n",
      "'count' is similar to 'home'\n",
      "'count' is similar to 'boy'\n",
      "'passed' is similar to 'chair'\n",
      "'son' is similar to 'wife'\n",
      "'son' is similar to 'husband'\n",
      "'son' is similar to 'enemy'\n",
      "'son' is similar to 'suffering'\n",
      "'new' is similar to 'quiet'\n",
      "'new' is similar to 'calm'\n",
      "'new' is similar to 'bright'\n",
      "'white' is similar to 'black'\n",
      "'white' is similar to 'dark'\n",
      "'white' is similar to 'low'\n",
      "'husband' is similar to 'man'\n",
      "'husband' is similar to 'father'\n",
      "'husband' is similar to 'wife'\n",
      "'husband' is similar to 'woman'\n",
      "'husband' is similar to 'son'\n",
      "'husband' is similar to 'tea'\n",
      "'small' is similar to 'large'\n",
      "'officer' is similar to 'wife'\n",
      "'officer' is similar to 'fire'\n",
      "'officer' is similar to 'lady'\n",
      "'officer' is similar to 'boy'\n",
      "'officer' is similar to 'wolf'\n",
      "'officer' is similar to 'captain'\n",
      "'became' is similar to 'become'\n",
      "'became' is similar to 'grew'\n",
      "'called' is similar to 'pushed'\n",
      "'death' is similar to 'battle'\n",
      "'death' is similar to 'sleep'\n",
      "'death' is similar to 'town'\n",
      "'death' is similar to 'papers'\n",
      "'death' is similar to 'bridge'\n",
      "'death' is similar to 'prisoners'\n",
      "'death' is similar to 'girls'\n",
      "'word' is similar to 'army'\n",
      "'word' is similar to 'events'\n",
      "'word' is similar to 'condition'\n",
      "'word' is similar to 'food'\n",
      "'till' is similar to 'since'\n",
      "'till' is similar to 'until'\n",
      "'light' is similar to 'interest'\n",
      "'light' is similar to 'court'\n",
      "'lay' is similar to 'sat'\n",
      "'better' is similar to 'less'\n",
      "'gone' is similar to 'go'\n",
      "'gone' is similar to 'going'\n",
      "'table' is similar to 'lips'\n",
      "'table' is similar to 'joy'\n",
      "'table' is similar to 'step'\n",
      "'table' is similar to 'generals'\n",
      "'window' is similar to 'hand'\n",
      "'window' is similar to 'bed'\n",
      "'window' is similar to 'arm'\n",
      "'window' is similar to 'smoke'\n",
      "'window' is similar to 'peace'\n",
      "'does' is similar to 'did'\n",
      "'does' is similar to 'do'\n",
      "'evening' is similar to 'floor'\n",
      "'evening' is similar to 'sofa'\n",
      "'bed' is similar to 'window'\n",
      "'bed' is similar to 'horse'\n",
      "'bed' is similar to 'arm'\n",
      "'bed' is similar to 'peace'\n",
      "'bed' is similar to 'clothes'\n",
      "'bed' is similar to 'anger'\n",
      "'world' is similar to 'line'\n",
      "'world' is similar to 'regiment'\n",
      "'world' is similar to 'rooms'\n",
      "'world' is similar to 'prisoners'\n",
      "'world' is similar to 'girls'\n",
      "'poor' is similar to 'young'\n",
      "'order' is similar to 'desire'\n",
      "'horse' is similar to 'bed'\n",
      "'horse' is similar to 'road'\n",
      "'horse' is similar to 'forward'\n",
      "'horse' is similar to 'clothes'\n",
      "'horse' is similar to 'generals'\n",
      "'coming' is similar to 'straight'\n",
      "'fell' is similar to 'fall'\n",
      "'fell' is similar to 'fallen'\n",
      "'fell' is similar to 'thrown'\n",
      "'fire' is similar to 'officer'\n",
      "'fire' is similar to 'road'\n",
      "'fire' is similar to 'clothes'\n",
      "'sent' is similar to 'led'\n",
      "'since' is similar to 'till'\n",
      "'since' is similar to 'until'\n",
      "'near' is similar to 'up'\n",
      "'near' is similar to 'over'\n",
      "'themselves' is similar to 'pain'\n",
      "'themselves' is similar to 'throat'\n",
      "'saying' is similar to 'say'\n",
      "'longer' is similar to 'knife'\n",
      "'battle' is similar to 'death'\n",
      "'battle' is similar to 'sleep'\n",
      "'battle' is similar to 'events'\n",
      "'battle' is similar to 'papers'\n",
      "'soldiers' is similar to 'men'\n",
      "'soldiers' is similar to 'generals'\n",
      "'train' is similar to 'sun'\n",
      "'fear' is similar to 'idea'\n",
      "'sleep' is similar to 'death'\n",
      "'sleep' is similar to 'battle'\n",
      "'sleep' is similar to 'papers'\n",
      "'sleep' is similar to 'rooms'\n",
      "'ready' is similar to 'time'\n",
      "'wanted' is similar to 'difficult'\n",
      "'entered' is similar to 'outside'\n",
      "'horses' is similar to 'others'\n",
      "'horses' is similar to 'officers'\n",
      "'horses' is similar to 'peasants'\n",
      "'letter' is similar to 'terror'\n",
      "'letter' is similar to 'passion'\n",
      "'opened' is similar to 'closed'\n",
      "'expression' is similar to 'smile'\n",
      "'hair' is similar to 'face'\n",
      "'hair' is similar to 'head'\n",
      "'hair' is similar to 'shoulders'\n",
      "'hair' is similar to 'marriage'\n",
      "'strange' is similar to 'bad'\n",
      "'hear' is similar to 'knew'\n",
      "'held' is similar to 'keep'\n",
      "'met' is similar to 'reached'\n",
      "'met' is similar to 'watched'\n",
      "'course' is similar to 'afraid'\n",
      "'able' is similar to 'tried'\n",
      "'able' is similar to 'unable'\n",
      "'happy' is similar to 'evil'\n",
      "'happy' is similar to 'worse'\n",
      "'returned' is similar to 'forward'\n",
      "'returned' is similar to 'return'\n",
      "'returned' is similar to 'shoulders'\n",
      "'road' is similar to 'door'\n",
      "'road' is similar to 'horse'\n",
      "'road' is similar to 'fire'\n",
      "'road' is similar to 'shoulders'\n",
      "'road' is similar to 'move'\n",
      "'black' is similar to 'white'\n",
      "'girl' is similar to 'man'\n",
      "'girl' is similar to 'person'\n",
      "'rose' is similar to 'up'\n",
      "'taking' is similar to 'took'\n",
      "'taking' is similar to 'take'\n",
      "'large' is similar to 'small'\n",
      "'lady' is similar to 'father'\n",
      "'lady' is similar to 'wife'\n",
      "'lady' is similar to 'woman'\n",
      "'lady' is similar to 'officer'\n",
      "'lady' is similar to 'wolf'\n",
      "'keep' is similar to 'put'\n",
      "'keep' is similar to 'held'\n",
      "'true' is similar to 'general'\n",
      "'true' is similar to 'escape'\n",
      "'war' is similar to 'officers'\n",
      "'war' is similar to 'dress'\n",
      "'war' is similar to 'party'\n",
      "'war' is similar to 'hill'\n",
      "'war' is similar to 'age'\n",
      "'beside' is similar to 'find'\n",
      "'sound' is similar to 'appearance'\n",
      "'blood' is similar to 'pain'\n",
      "'body' is similar to 'others'\n",
      "'body' is similar to 'quickly'\n",
      "'body' is similar to 'neck'\n",
      "'body' is similar to 'guns'\n",
      "'enemy' is similar to 'general'\n",
      "'enemy' is similar to 'son'\n",
      "'tried' is similar to 'able'\n",
      "'tried' is similar to 'desire'\n",
      "'enough' is similar to 'glad'\n",
      "'enough' is similar to 'sorry'\n",
      "'kind' is similar to 'gesture'\n",
      "'moved' is similar to 'rushed'\n",
      "'moved' is similar to 'walk'\n",
      "'moved' is similar to 'stepped'\n",
      "'forward' is similar to 'horse'\n",
      "'forward' is similar to 'returned'\n",
      "'daughter' is similar to 'sister'\n",
      "'standing' is similar to 'stood'\n",
      "'beautiful' is similar to 'simple'\n",
      "'arms' is similar to 'hand'\n",
      "'business' is similar to 'matters'\n",
      "'free' is similar to 'quick'\n",
      "'dark' is similar to 'white'\n",
      "'dark' is similar to 'high'\n",
      "'dark' is similar to 'low'\n",
      "'dark' is similar to 'calm'\n",
      "'followed' is similar to 'passing'\n",
      "'feet' is similar to 'smiled'\n",
      "'feet' is similar to 'floor'\n",
      "'feet' is similar to 'finger'\n",
      "'feet' is similar to 'ears'\n",
      "'feet' is similar to 'sofa'\n",
      "'feet' is similar to 'slept'\n",
      "'country' is similar to 'line'\n",
      "'country' is similar to 'town'\n",
      "'country' is similar to 'neck'\n",
      "'country' is similar to 'floor'\n",
      "'country' is similar to 'forest'\n",
      "'country' is similar to 'papers'\n",
      "'country' is similar to 'sky'\n",
      "'added' is similar to 'answered'\n",
      "'added' is similar to 'exclaimed'\n",
      "'become' is similar to 'became'\n",
      "'less' is similar to 'better'\n",
      "'line' is similar to 'world'\n",
      "'line' is similar to 'country'\n",
      "'line' is similar to 'ground'\n",
      "'line' is similar to 'regiment'\n",
      "'line' is similar to 'town'\n",
      "'line' is similar to 'forest'\n",
      "'line' is similar to 'stone'\n",
      "'line' is similar to 'garden'\n",
      "'line' is similar to 'court'\n",
      "'line' is similar to 'rooms'\n",
      "'water' is similar to 'journey'\n",
      "'water' is similar to 'fight'\n",
      "'cause' is similar to 'asking'\n",
      "'hour' is similar to 'minute'\n",
      "'toward' is similar to 'towards'\n",
      "'seeing' is similar to 'forget'\n",
      "'until' is similar to 'till'\n",
      "'until' is similar to 'since'\n",
      "'cold' is similar to 'safe'\n",
      "'fact' is similar to 'doubt'\n",
      "'run' is similar to 'farther'\n",
      "'troops' is similar to 'police'\n",
      "'troops' is similar to 'prisoners'\n",
      "'troops' is similar to 'guns'\n",
      "'turning' is similar to 'running'\n",
      "'ground' is similar to 'line'\n",
      "'ground' is similar to 'town'\n",
      "'ground' is similar to 'study'\n",
      "'ground' is similar to 'forest'\n",
      "'ground' is similar to 'garden'\n",
      "'ground' is similar to 'river'\n",
      "'ground' is similar to 'passage'\n",
      "'ground' is similar to 'pocket'\n",
      "'ground' is similar to 'sofa'\n",
      "'afraid' is similar to 'course'\n",
      "'afraid' is similar to 'sure'\n",
      "'afraid' is similar to 'suppose'\n",
      "'lips' is similar to 'table'\n",
      "'lips' is similar to 'horror'\n",
      "'lips' is similar to 'forehead'\n",
      "'arm' is similar to 'window'\n",
      "'arm' is similar to 'bed'\n",
      "'arm' is similar to 'peace'\n",
      "'arm' is similar to 'figure'\n",
      "'arm' is similar to 'anger'\n",
      "'anyone' is similar to 'man'\n",
      "'anyone' is similar to 'everyone'\n",
      "'anyone' is similar to 'someone'\n",
      "'anyone' is similar to 'everybody'\n",
      "'doubt' is similar to 'fact'\n",
      "'during' is similar to 'from'\n",
      "'soldier' is similar to 'himself'\n",
      "'soldier' is similar to 'brother'\n",
      "'soldier' is similar to 'uniform'\n",
      "'drew' is similar to 'holding'\n",
      "'sure' is similar to 'afraid'\n",
      "'sure' is similar to 'suppose'\n",
      "'rode' is similar to 'went'\n",
      "'rode' is similar to 'ran'\n",
      "'rode' is similar to 'straight'\n",
      "'rode' is similar to 'walked'\n",
      "'rode' is similar to 'rushed'\n",
      "'rode' is similar to 'galloped'\n",
      "'understood' is similar to 'know'\n",
      "'understood' is similar to 'understanding'\n",
      "'idea' is similar to 'fear'\n",
      "'idea' is similar to 'story'\n",
      "'children' is similar to 'people'\n",
      "'children' is similar to 'officers'\n",
      "'children' is similar to 'girls'\n",
      "'children' is similar to 'age'\n",
      "'doctor' is similar to 'captain'\n",
      "'noticed' is similar to 'saw'\n",
      "'noticed' is similar to 'loved'\n",
      "'sir' is similar to 'city'\n",
      "'dinner' is similar to 'wood'\n",
      "'clear' is similar to 'start'\n",
      "'return' is similar to 'returned'\n",
      "'silence' is similar to 'hours'\n",
      "'silence' is similar to 'affair'\n",
      "'silence' is similar to 'beauty'\n",
      "'silence' is similar to 'river'\n",
      "'silence' is similar to 'passage'\n",
      "'impossible' is similar to 'trying'\n",
      "'bring' is similar to 'give'\n",
      "'bring' is similar to 'giving'\n",
      "'women' is similar to 'people'\n",
      "'women' is similar to 'gentleman'\n",
      "'women' is similar to 'suffering'\n",
      "'officers' is similar to 'people'\n",
      "'officers' is similar to 'horses'\n",
      "'officers' is similar to 'war'\n",
      "'officers' is similar to 'children'\n",
      "'officers' is similar to 'quickly'\n",
      "'officers' is similar to 'events'\n",
      "'officers' is similar to 'coat'\n",
      "'officers' is similar to 'rooms'\n",
      "'officers' is similar to 'prisoners'\n",
      "'officers' is similar to 'windows'\n",
      "'officers' is similar to 'guns'\n",
      "'officers' is similar to 'hill'\n",
      "'making' is similar to 'made'\n",
      "'making' is similar to 'make'\n",
      "'late' is similar to 'paused'\n",
      "'drawing' is similar to 'lit'\n",
      "'boy' is similar to 'wife'\n",
      "'boy' is similar to 'count'\n",
      "'boy' is similar to 'officer'\n",
      "'boy' is similar to 'nature'\n",
      "'boy' is similar to 'wolf'\n",
      "'boy' is similar to 'character'\n",
      "'pleasure' is similar to 'ball'\n",
      "'reached' is similar to 'met'\n",
      "'bad' is similar to 'strange'\n",
      "'grew' is similar to 'became'\n",
      "'nature' is similar to 'boy'\n",
      "'carried' is similar to 'set'\n",
      "'carried' is similar to 'pressed'\n",
      "'carried' is similar to 'sprang'\n",
      "'carried' is similar to 'thrown'\n",
      "'four' is similar to 'two'\n",
      "'four' is similar to 'three'\n",
      "'four' is similar to 'hundred'\n",
      "'four' is similar to 'ten'\n",
      "'quickly' is similar to 'body'\n",
      "'quickly' is similar to 'officers'\n",
      "'quickly' is similar to 'rapidly'\n",
      "'quickly' is similar to 'guns'\n",
      "'later' is similar to 'hall'\n",
      "'high' is similar to 'dark'\n",
      "'high' is similar to 'calm'\n",
      "'high' is similar to 'bright'\n",
      "'high' is similar to 'simple'\n",
      "'everyone' is similar to 'she'\n",
      "'everyone' is similar to 'anyone'\n",
      "'everyone' is similar to 'someone'\n",
      "'led' is similar to 'got'\n",
      "'led' is similar to 'brought'\n",
      "'led' is similar to 'sent'\n",
      "'hope' is similar to 'think'\n",
      "'use' is similar to 'hold'\n",
      "'remember' is similar to 'remarked'\n",
      "'brother' is similar to 'soldier'\n",
      "'brother' is similar to 'uniform'\n",
      "'several' is similar to 'three'\n",
      "'ve' is similar to 'having'\n",
      "'manner' is similar to 'reply'\n",
      "'manner' is similar to 'express'\n",
      "'manner' is similar to 'dream'\n",
      "'carriage' is similar to 'snow'\n",
      "'carriage' is similar to 'floor'\n",
      "'carriage' is similar to 'journey'\n",
      "'carriage' is similar to 'ears'\n",
      "'strength' is similar to 'gesture'\n",
      "'strength' is similar to 'character'\n",
      "'hundred' is similar to 'two'\n",
      "'hundred' is similar to 'three'\n",
      "'hundred' is similar to 'four'\n",
      "'hundred' is similar to 'ten'\n",
      "'regiment' is similar to 'world'\n",
      "'regiment' is similar to 'line'\n",
      "'regiment' is similar to 'garden'\n",
      "'regiment' is similar to 'rooms'\n",
      "'regiment' is similar to 'clothes'\n",
      "'regiment' is similar to 'generals'\n",
      "'known' is similar to 'opinion'\n",
      "'laid' is similar to 'put'\n",
      "'laid' is similar to 'placed'\n",
      "'often' is similar to 'simply'\n",
      "'different' is similar to 'advanced'\n",
      "'smiled' is similar to 'feet'\n",
      "'smiled' is similar to 'finger'\n",
      "'smiled' is similar to 'shouting'\n",
      "'closed' is similar to 'opened'\n",
      "'town' is similar to 'death'\n",
      "'town' is similar to 'country'\n",
      "'town' is similar to 'line'\n",
      "'town' is similar to 'ground'\n",
      "'town' is similar to 'neck'\n",
      "'town' is similar to 'ago'\n",
      "'town' is similar to 'forest'\n",
      "'town' is similar to 'papers'\n",
      "'town' is similar to 'stone'\n",
      "'town' is similar to 'garden'\n",
      "'town' is similar to 'sky'\n",
      "'town' is similar to 'engine'\n",
      "'town' is similar to 'rooms'\n",
      "'town' is similar to 'passage'\n",
      "'town' is similar to 'pocket'\n",
      "'town' is similar to 'slept'\n",
      "'corner' is similar to 'middle'\n",
      "'steps' is similar to 'slowly'\n",
      "'asleep' is similar to 'floor'\n",
      "'seem' is similar to 'seemed'\n",
      "'family' is similar to 'express'\n",
      "'loved' is similar to 'noticed'\n",
      "'truth' is similar to 'alone'\n",
      "'truth' is similar to 'servants'\n",
      "'five' is similar to 'ten'\n",
      "'five' is similar to 'twenty'\n",
      "'glad' is similar to 'enough'\n",
      "'sun' is similar to 'train'\n",
      "'threw' is similar to 'put'\n",
      "'trying' is similar to 'impossible'\n",
      "'remarked' is similar to 'remember'\n",
      "'remarked' is similar to 'understanding'\n",
      "'snow' is similar to 'carriage'\n",
      "'show' is similar to 'tell'\n",
      "'show' is similar to 'showed'\n",
      "'showed' is similar to 'show'\n",
      "'straight' is similar to 'ran'\n",
      "'straight' is similar to 'coming'\n",
      "'straight' is similar to 'rode'\n",
      "'straight' is similar to 'rushed'\n",
      "'straight' is similar to 'galloped'\n",
      "'straight' is similar to 'stepped'\n",
      "'ten' is similar to 'two'\n",
      "'ten' is similar to 'three'\n",
      "'ten' is similar to 'few'\n",
      "'ten' is similar to 'four'\n",
      "'ten' is similar to 'hundred'\n",
      "'ten' is similar to 'five'\n",
      "'ten' is similar to 'twenty'\n",
      "'pass' is similar to 'rooms'\n",
      "'service' is similar to 'cry'\n",
      "'service' is similar to 'wind'\n",
      "'try' is similar to 'began'\n",
      "'try' is similar to 'begin'\n",
      "'presence' is similar to 'gesture'\n",
      "'presence' is similar to 'character'\n",
      "'towards' is similar to 'toward'\n",
      "'mouth' is similar to 'hand'\n",
      "'mouth' is similar to 'voices'\n",
      "'mouth' is similar to 'foot'\n",
      "'study' is similar to 'ground'\n",
      "'study' is similar to 'river'\n",
      "'gold' is similar to 'joy'\n",
      "'gold' is similar to 'hall'\n",
      "'gold' is similar to 'sofa'\n",
      "'low' is similar to 'white'\n",
      "'low' is similar to 'dark'\n",
      "'story' is similar to 'work'\n",
      "'story' is similar to 'idea'\n",
      "'placed' is similar to 'laid'\n",
      "'reply' is similar to 'time'\n",
      "'reply' is similar to 'manner'\n",
      "'reply' is similar to 'captain'\n",
      "'walked' is similar to 'ran'\n",
      "'walked' is similar to 'rode'\n",
      "'walked' is similar to 'running'\n",
      "'walked' is similar to 'galloped'\n",
      "'desire' is similar to 'order'\n",
      "'desire' is similar to 'tried'\n",
      "'kill' is similar to 'marry'\n",
      "'wood' is similar to 'dinner'\n",
      "'wood' is similar to 'shoulders'\n",
      "'wood' is similar to 'move'\n",
      "'wood' is similar to 'gate'\n",
      "'wood' is similar to 'empty'\n",
      "'wood' is similar to 'satisfied'\n",
      "'exclaimed' is similar to 'added'\n",
      "'glanced' is similar to 'looked'\n",
      "'glanced' is similar to 'looking'\n",
      "'glanced' is similar to 'glance'\n",
      "'glanced' is similar to 'gazed'\n",
      "'sister' is similar to 'daughter'\n",
      "'fall' is similar to 'fell'\n",
      "'fall' is similar to 'fallen'\n",
      "'cry' is similar to 'service'\n",
      "'cry' is similar to 'future'\n",
      "'cry' is similar to 'servants'\n",
      "'running' is similar to 'looking'\n",
      "'running' is similar to 'turning'\n",
      "'running' is similar to 'walked'\n",
      "'running' is similar to 'stepped'\n",
      "'smoke' is similar to 'window'\n",
      "'smoke' is similar to 'sea'\n",
      "'someone' is similar to 'man'\n",
      "'someone' is similar to 'anyone'\n",
      "'someone' is similar to 'everyone'\n",
      "'happiness' is similar to 'joy'\n",
      "'neck' is similar to 'body'\n",
      "'neck' is similar to 'country'\n",
      "'neck' is similar to 'town'\n",
      "'neck' is similar to 'bridge'\n",
      "'neck' is similar to 'court'\n",
      "'neck' is similar to 'sky'\n",
      "'neck' is similar to 'windows'\n",
      "'shoulders' is similar to 'door'\n",
      "'shoulders' is similar to 'hands'\n",
      "'shoulders' is similar to 'hair'\n",
      "'shoulders' is similar to 'returned'\n",
      "'shoulders' is similar to 'road'\n",
      "'shoulders' is similar to 'wood'\n",
      "'shoulders' is similar to 'move'\n",
      "'shoulders' is similar to 'knife'\n",
      "'shoulders' is similar to 'forehead'\n",
      "'certainly' is similar to 'ever'\n",
      "'holding' is similar to 'drew'\n",
      "'holding' is similar to 'send'\n",
      "'re' is similar to 'is'\n",
      "'re' is similar to 'were'\n",
      "'hold' is similar to 'use'\n",
      "'events' is similar to 'army'\n",
      "'events' is similar to 'words'\n",
      "'events' is similar to 'word'\n",
      "'events' is similar to 'battle'\n",
      "'events' is similar to 'officers'\n",
      "'events' is similar to 'papers'\n",
      "'events' is similar to 'rooms'\n",
      "'events' is similar to 'prisoners'\n",
      "'coat' is similar to 'officers'\n",
      "'voices' is similar to 'voice'\n",
      "'voices' is similar to 'mouth'\n",
      "'voices' is similar to 'generals'\n",
      "'chair' is similar to 'passed'\n",
      "'chair' is similar to 'breath'\n",
      "'important' is similar to 'further'\n",
      "'simply' is similar to 'often'\n",
      "'interest' is similar to 'light'\n",
      "'station' is similar to 'darkness'\n",
      "'opinion' is similar to 'known'\n",
      "'act' is similar to 'look'\n",
      "'dress' is similar to 'war'\n",
      "'dress' is similar to 'hill'\n",
      "'account' is similar to 'eye'\n",
      "'ago' is similar to 'town'\n",
      "'ago' is similar to 'papers'\n",
      "'beyond' is similar to 'by'\n",
      "'beyond' is similar to 'into'\n",
      "'beyond' is similar to 'through'\n",
      "'hours' is similar to 'silence'\n",
      "'hours' is similar to 'view'\n",
      "'hours' is similar to 'dream'\n",
      "'move' is similar to 'down'\n",
      "'move' is similar to 'door'\n",
      "'move' is similar to 'road'\n",
      "'move' is similar to 'wood'\n",
      "'move' is similar to 'shoulders'\n",
      "'move' is similar to 'knife'\n",
      "'floor' is similar to 'evening'\n",
      "'floor' is similar to 'feet'\n",
      "'floor' is similar to 'country'\n",
      "'floor' is similar to 'carriage'\n",
      "'floor' is similar to 'asleep'\n",
      "'floor' is similar to 'journey'\n",
      "'floor' is similar to 'sofa'\n",
      "'floor' is similar to 'slept'\n",
      "'kissed' is similar to 'behind'\n",
      "'kissed' is similar to 'interrupted'\n",
      "'peace' is similar to 'window'\n",
      "'peace' is similar to 'bed'\n",
      "'peace' is similar to 'arm'\n",
      "'peace' is similar to 'anger'\n",
      "'forest' is similar to 'country'\n",
      "'forest' is similar to 'line'\n",
      "'forest' is similar to 'ground'\n",
      "'forest' is similar to 'town'\n",
      "'forest' is similar to 'court'\n",
      "'forest' is similar to 'rooms'\n",
      "'forest' is similar to 'paused'\n",
      "'forest' is similar to 'cap'\n",
      "'forest' is similar to 'passage'\n",
      "'forest' is similar to 'pocket'\n",
      "'forest' is similar to 'slept'\n",
      "'passing' is similar to 'followed'\n",
      "'quiet' is similar to 'new'\n",
      "'quiet' is similar to 'sad'\n",
      "'quiet' is similar to 'calm'\n",
      "'quiet' is similar to 'warm'\n",
      "'unable' is similar to 'able'\n",
      "'giving' is similar to 'gave'\n",
      "'giving' is similar to 'give'\n",
      "'giving' is similar to 'bring'\n",
      "'wolf' is similar to 'officer'\n",
      "'wolf' is similar to 'lady'\n",
      "'wolf' is similar to 'boy'\n",
      "'wolf' is similar to 'captain'\n",
      "'wolf' is similar to 'colonel'\n",
      "'foot' is similar to 'mouth'\n",
      "'foot' is similar to 'figure'\n",
      "'friends' is similar to 'drink'\n",
      "'papers' is similar to 'death'\n",
      "'papers' is similar to 'battle'\n",
      "'papers' is similar to 'sleep'\n",
      "'papers' is similar to 'country'\n",
      "'papers' is similar to 'town'\n",
      "'papers' is similar to 'events'\n",
      "'papers' is similar to 'ago'\n",
      "'papers' is similar to 'stone'\n",
      "'papers' is similar to 'rooms'\n",
      "'danger' is similar to 'path'\n",
      "'joy' is similar to 'table'\n",
      "'joy' is similar to 'gold'\n",
      "'joy' is similar to 'happiness'\n",
      "'box' is similar to 'work'\n",
      "'box' is similar to 'servants'\n",
      "'outside' is similar to 'entered'\n",
      "'outside' is similar to 'changed'\n",
      "'handsome' is similar to 'quick'\n",
      "'bird' is similar to 'maid'\n",
      "'further' is similar to 'important'\n",
      "'further' is similar to 'deal'\n",
      "'step' is similar to 'table'\n",
      "'view' is similar to 'hours'\n",
      "'view' is similar to 'dream'\n",
      "'letters' is similar to 'day'\n",
      "'wind' is similar to 'service'\n",
      "'wind' is similar to 'teeth'\n",
      "'bridge' is similar to 'death'\n",
      "'bridge' is similar to 'neck'\n",
      "'evil' is similar to 'happy'\n",
      "'sad' is similar to 'quiet'\n",
      "'police' is similar to 'others'\n",
      "'police' is similar to 'troops'\n",
      "'police' is similar to 'guns'\n",
      "'rushed' is similar to 'came'\n",
      "'rushed' is similar to 'ran'\n",
      "'rushed' is similar to 'moved'\n",
      "'rushed' is similar to 'rode'\n",
      "'rushed' is similar to 'straight'\n",
      "'rushed' is similar to 'galloped'\n",
      "'rushed' is similar to 'stepped'\n",
      "'asking' is similar to 'cause'\n",
      "'ball' is similar to 'pleasure'\n",
      "'calm' is similar to 'new'\n",
      "'calm' is similar to 'dark'\n",
      "'calm' is similar to 'high'\n",
      "'calm' is similar to 'quiet'\n",
      "'calm' is similar to 'bright'\n",
      "'calm' is similar to 'simple'\n",
      "'changed' is similar to 'outside'\n",
      "'pain' is similar to 'themselves'\n",
      "'pain' is similar to 'blood'\n",
      "'eye' is similar to 'account'\n",
      "'surprised' is similar to 'horror'\n",
      "'stone' is similar to 'line'\n",
      "'stone' is similar to 'town'\n",
      "'stone' is similar to 'papers'\n",
      "'stone' is similar to 'passage'\n",
      "'matters' is similar to 'business'\n",
      "'person' is similar to 'girl'\n",
      "'bright' is similar to 'new'\n",
      "'bright' is similar to 'high'\n",
      "'bright' is similar to 'calm'\n",
      "'gentleman' is similar to 'man'\n",
      "'gentleman' is similar to 'woman'\n",
      "'gentleman' is similar to 'women'\n",
      "'figure' is similar to 'head'\n",
      "'figure' is similar to 'arm'\n",
      "'figure' is similar to 'foot'\n",
      "'glance' is similar to 'looked'\n",
      "'glance' is similar to 'glanced'\n",
      "'quick' is similar to 'free'\n",
      "'quick' is similar to 'handsome'\n",
      "'real' is similar to 'own'\n",
      "'spot' is similar to 'house'\n",
      "'spot' is similar to 'place'\n",
      "'fallen' is similar to 'fell'\n",
      "'fallen' is similar to 'fall'\n",
      "'send' is similar to 'holding'\n",
      "'suppose' is similar to 'afraid'\n",
      "'suppose' is similar to 'sure'\n",
      "'law' is similar to 'beauty'\n",
      "'walk' is similar to 'moved'\n",
      "'tree' is similar to 'knife'\n",
      "'affair' is similar to 'silence'\n",
      "'affair' is similar to 'beauty'\n",
      "'direction' is similar to 'sea'\n",
      "'express' is similar to 'manner'\n",
      "'express' is similar to 'family'\n",
      "'begin' is similar to 'began'\n",
      "'begin' is similar to 'try'\n",
      "'journey' is similar to 'water'\n",
      "'journey' is similar to 'carriage'\n",
      "'journey' is similar to 'floor'\n",
      "'simple' is similar to 'beautiful'\n",
      "'simple' is similar to 'high'\n",
      "'simple' is similar to 'calm'\n",
      "'garden' is similar to 'line'\n",
      "'garden' is similar to 'ground'\n",
      "'garden' is similar to 'regiment'\n",
      "'garden' is similar to 'town'\n",
      "'garden' is similar to 'pocket'\n",
      "'court' is similar to 'light'\n",
      "'court' is similar to 'line'\n",
      "'court' is similar to 'neck'\n",
      "'court' is similar to 'forest'\n",
      "'laughing' is similar to 'disappeared'\n",
      "'laughing' is similar to 'places'\n",
      "'marry' is similar to 'kill'\n",
      "'pressed' is similar to 'carried'\n",
      "'captain' is similar to 'officer'\n",
      "'captain' is similar to 'doctor'\n",
      "'captain' is similar to 'reply'\n",
      "'captain' is similar to 'wolf'\n",
      "'forget' is similar to 'seeing'\n",
      "'interrupted' is similar to 'behind'\n",
      "'interrupted' is similar to 'kissed'\n",
      "'peasants' is similar to 'horses'\n",
      "'middle' is similar to 'corner'\n",
      "'minute' is similar to 'hour'\n",
      "'ill' is similar to 'escape'\n",
      "'knife' is similar to 'longer'\n",
      "'knife' is similar to 'shoulders'\n",
      "'knife' is similar to 'move'\n",
      "'knife' is similar to 'tree'\n",
      "'knife' is similar to 'forehead'\n",
      "'sky' is similar to 'morning'\n",
      "'sky' is similar to 'country'\n",
      "'sky' is similar to 'town'\n",
      "'sky' is similar to 'neck'\n",
      "'sky' is similar to 'pocket'\n",
      "'drink' is similar to 'friends'\n",
      "'imagine' is similar to 'see'\n",
      "'effect' is similar to 'ring'\n",
      "'seat' is similar to 'horror'\n",
      "'engine' is similar to 'town'\n",
      "'engine' is similar to 'pocket'\n",
      "'rapidly' is similar to 'hand'\n",
      "'rapidly' is similar to 'quickly'\n",
      "'rapidly' is similar to 'generals'\n",
      "'rooms' is similar to 'army'\n",
      "'rooms' is similar to 'world'\n",
      "'rooms' is similar to 'sleep'\n",
      "'rooms' is similar to 'line'\n",
      "'rooms' is similar to 'officers'\n",
      "'rooms' is similar to 'regiment'\n",
      "'rooms' is similar to 'town'\n",
      "'rooms' is similar to 'pass'\n",
      "'rooms' is similar to 'events'\n",
      "'rooms' is similar to 'forest'\n",
      "'rooms' is similar to 'papers'\n",
      "'rooms' is similar to 'prisoners'\n",
      "'rooms' is similar to 'shouting'\n",
      "'rooms' is similar to 'cap'\n",
      "'rooms' is similar to 'windows'\n",
      "'rooms' is similar to 'girls'\n",
      "'clothes' is similar to 'bed'\n",
      "'clothes' is similar to 'horse'\n",
      "'clothes' is similar to 'fire'\n",
      "'clothes' is similar to 'regiment'\n",
      "'difficult' is similar to 'wanted'\n",
      "'prisoners' is similar to 'death'\n",
      "'prisoners' is similar to 'world'\n",
      "'prisoners' is similar to 'troops'\n",
      "'prisoners' is similar to 'officers'\n",
      "'prisoners' is similar to 'events'\n",
      "'prisoners' is similar to 'rooms'\n",
      "'prisoners' is similar to 'girls'\n",
      "'darkness' is similar to 'station'\n",
      "'everybody' is similar to 'anyone'\n",
      "'maid' is similar to 'bird'\n",
      "'farther' is similar to 'ran'\n",
      "'farther' is similar to 'run'\n",
      "'finger' is similar to 'feet'\n",
      "'finger' is similar to 'smiled'\n",
      "'form' is similar to 'secret'\n",
      "'hall' is similar to 'later'\n",
      "'hall' is similar to 'gold'\n",
      "'sprang' is similar to 'carried'\n",
      "'sprang' is similar to 'thrown'\n",
      "'throat' is similar to 'themselves'\n",
      "'enter' is similar to 'down'\n",
      "'gate' is similar to 'wood'\n",
      "'teeth' is similar to 'wind'\n",
      "'teeth' is similar to 'slowly'\n",
      "'week' is similar to 'tomorrow'\n",
      "'activity' is similar to 'secret'\n",
      "'blow' is similar to 'terror'\n",
      "'deal' is similar to 'further'\n",
      "'empty' is similar to 'wood'\n",
      "'pointed' is similar to 'turned'\n",
      "'ears' is similar to 'feet'\n",
      "'ears' is similar to 'carriage'\n",
      "'ears' is similar to 'windows'\n",
      "'gazed' is similar to 'looked'\n",
      "'gazed' is similar to 'looking'\n",
      "'gazed' is similar to 'glanced'\n",
      "'twenty' is similar to 'five'\n",
      "'twenty' is similar to 'ten'\n",
      "'path' is similar to 'danger'\n",
      "'sea' is similar to 'smoke'\n",
      "'sea' is similar to 'direction'\n",
      "'future' is similar to 'cry'\n",
      "'future' is similar to 'servants'\n",
      "'marriage' is similar to 'hair'\n",
      "'paused' is similar to 'late'\n",
      "'paused' is similar to 'forest'\n",
      "'paused' is similar to 'cap'\n",
      "'shouting' is similar to 'smiled'\n",
      "'shouting' is similar to 'rooms'\n",
      "'stand' is similar to 'slowly'\n",
      "'aside' is similar to 'pocket'\n",
      "'beauty' is similar to 'silence'\n",
      "'beauty' is similar to 'law'\n",
      "'beauty' is similar to 'affair'\n",
      "'mine' is similar to 'me'\n",
      "'cap' is similar to 'house'\n",
      "'cap' is similar to 'forest'\n",
      "'cap' is similar to 'rooms'\n",
      "'cap' is similar to 'paused'\n",
      "'cap' is similar to 'windows'\n",
      "'cap' is similar to 'slept'\n",
      "'disappeared' is similar to 'laughing'\n",
      "'lit' is similar to 'drawing'\n",
      "'river' is similar to 'hand'\n",
      "'river' is similar to 'ground'\n",
      "'river' is similar to 'silence'\n",
      "'river' is similar to 'study'\n",
      "'river' is similar to 'passage'\n",
      "'thrown' is similar to 'fell'\n",
      "'thrown' is similar to 'carried'\n",
      "'thrown' is similar to 'sprang'\n",
      "'watched' is similar to 'met'\n",
      "'city' is similar to 'sir'\n",
      "'understanding' is similar to 'understood'\n",
      "'understanding' is similar to 'remarked'\n",
      "'condition' is similar to 'army'\n",
      "'condition' is similar to 'word'\n",
      "'satisfied' is similar to 'wood'\n",
      "'slowly' is similar to 'head'\n",
      "'slowly' is similar to 'hands'\n",
      "'slowly' is similar to 'steps'\n",
      "'slowly' is similar to 'teeth'\n",
      "'slowly' is similar to 'stand'\n",
      "'start' is similar to 'clear'\n",
      "'tomorrow' is similar to 'here'\n",
      "'tomorrow' is similar to 'week'\n",
      "'windows' is similar to 'others'\n",
      "'windows' is similar to 'officers'\n",
      "'windows' is similar to 'neck'\n",
      "'windows' is similar to 'rooms'\n",
      "'windows' is similar to 'ears'\n",
      "'windows' is similar to 'cap'\n",
      "'windows' is similar to 'guns'\n",
      "'fight' is similar to 'water'\n",
      "'horror' is similar to 'lips'\n",
      "'horror' is similar to 'surprised'\n",
      "'horror' is similar to 'seat'\n",
      "'ring' is similar to 'effect'\n",
      "'servants' is similar to 'work'\n",
      "'servants' is similar to 'truth'\n",
      "'servants' is similar to 'cry'\n",
      "'servants' is similar to 'box'\n",
      "'servants' is similar to 'future'\n",
      "'servants' is similar to 'hussars'\n",
      "'colonel' is similar to 'wolf'\n",
      "'sorry' is similar to 'enough'\n",
      "'special' is similar to 'good'\n",
      "'warm' is similar to 'quiet'\n",
      "'passage' is similar to 'ground'\n",
      "'passage' is similar to 'silence'\n",
      "'passage' is similar to 'town'\n",
      "'passage' is similar to 'forest'\n",
      "'passage' is similar to 'stone'\n",
      "'passage' is similar to 'river'\n",
      "'pocket' is similar to 'ground'\n",
      "'pocket' is similar to 'town'\n",
      "'pocket' is similar to 'forest'\n",
      "'pocket' is similar to 'garden'\n",
      "'pocket' is similar to 'sky'\n",
      "'pocket' is similar to 'engine'\n",
      "'pocket' is similar to 'aside'\n",
      "'shot' is similar to 'drive'\n",
      "'suffering' is similar to 'son'\n",
      "'suffering' is similar to 'women'\n",
      "'terror' is similar to 'letter'\n",
      "'terror' is similar to 'blow'\n",
      "'drive' is similar to 'shot'\n",
      "'party' is similar to 'war'\n",
      "'secret' is similar to 'form'\n",
      "'secret' is similar to 'activity'\n",
      "'advanced' is similar to 'different'\n",
      "'girls' is similar to 'death'\n",
      "'girls' is similar to 'world'\n",
      "'girls' is similar to 'children'\n",
      "'girls' is similar to 'rooms'\n",
      "'girls' is similar to 'prisoners'\n",
      "'sofa' is similar to 'evening'\n",
      "'sofa' is similar to 'feet'\n",
      "'sofa' is similar to 'ground'\n",
      "'sofa' is similar to 'gold'\n",
      "'sofa' is similar to 'floor'\n",
      "'appearance' is similar to 'sound'\n",
      "'breath' is similar to 'chair'\n",
      "'difficulty' is similar to 'work'\n",
      "'dream' is similar to 'manner'\n",
      "'dream' is similar to 'hours'\n",
      "'dream' is similar to 'view'\n",
      "'food' is similar to 'word'\n",
      "'galloped' is similar to 'ran'\n",
      "'galloped' is similar to 'rode'\n",
      "'galloped' is similar to 'straight'\n",
      "'galloped' is similar to 'walked'\n",
      "'galloped' is similar to 'rushed'\n",
      "'galloped' is similar to 'stepped'\n",
      "'gesture' is similar to 'kind'\n",
      "'gesture' is similar to 'strength'\n",
      "'gesture' is similar to 'presence'\n",
      "'passion' is similar to 'general'\n",
      "'passion' is similar to 'letter'\n",
      "'places' is similar to 'laughing'\n",
      "'slept' is similar to 'feet'\n",
      "'slept' is similar to 'town'\n",
      "'slept' is similar to 'floor'\n",
      "'slept' is similar to 'forest'\n",
      "'slept' is similar to 'cap'\n",
      "'carefully' is similar to 'face'\n",
      "'carefully' is similar to 'head'\n",
      "'escape' is similar to 'true'\n",
      "'escape' is similar to 'ill'\n",
      "'forehead' is similar to 'lips'\n",
      "'forehead' is similar to 'shoulders'\n",
      "'forehead' is similar to 'knife'\n",
      "'guns' is similar to 'others'\n",
      "'guns' is similar to 'body'\n",
      "'guns' is similar to 'troops'\n",
      "'guns' is similar to 'officers'\n",
      "'guns' is similar to 'quickly'\n",
      "'guns' is similar to 'police'\n",
      "'guns' is similar to 'windows'\n",
      "'hussars' is similar to 'servants'\n",
      "'stepped' is similar to 'moved'\n",
      "'stepped' is similar to 'straight'\n",
      "'stepped' is similar to 'running'\n",
      "'stepped' is similar to 'rushed'\n",
      "'stepped' is similar to 'galloped'\n",
      "'uniform' is similar to 'soldier'\n",
      "'uniform' is similar to 'brother'\n",
      "'worse' is similar to 'happy'\n",
      "'anger' is similar to 'bed'\n",
      "'anger' is similar to 'arm'\n",
      "'anger' is similar to 'peace'\n",
      "'hill' is similar to 'war'\n",
      "'hill' is similar to 'officers'\n",
      "'hill' is similar to 'dress'\n",
      "'tea' is similar to 'father'\n",
      "'tea' is similar to 'husband'\n",
      "'age' is similar to 'war'\n",
      "'age' is similar to 'children'\n",
      "'character' is similar to 'wife'\n",
      "'character' is similar to 'boy'\n",
      "'character' is similar to 'strength'\n",
      "'character' is similar to 'presence'\n",
      "'generals' is similar to 'men'\n",
      "'generals' is similar to 'voice'\n",
      "'generals' is similar to 'table'\n",
      "'generals' is similar to 'horse'\n",
      "'generals' is similar to 'soldiers'\n",
      "'generals' is similar to 'regiment'\n",
      "'generals' is similar to 'voices'\n",
      "'generals' is similar to 'rapidly'\n",
      "'pushed' is similar to 'called'\n",
      "'safe' is similar to 'cold'\n"
     ]
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=EPSILON)\n",
    "embd_weights = best_model.embeddings.weight\n",
    "cosineSimilarityMatrix = [[0 for i in range(embd_weights.shape[0])] for j in range(embd_weights.shape[0])]\n",
    "\n",
    "for i in range(embd_weights.shape[0]):\n",
    "    for j in range(embd_weights.shape[0]):\n",
    "        cosineSimilarityMatrix[i][j] = F.cosine_similarity(embd_weights[i], embd_weights[j], dim=0).item()\n",
    "\n",
    "\n",
    "for i in range(len(cosineSimilarityMatrix)):\n",
    "    for j in range(len(cosineSimilarityMatrix[0])):\n",
    "        if i == 0 or j == 0:\n",
    "                continue\n",
    "        elif 0.8 < cosineSimilarityMatrix[i][j] < 1.0:  # Parameter '0.5' describes how equal two vectors are and should be increased with more precise embeddings\n",
    "            print(\"\\'\" + index2word[i] + \"\\'\" + \" is similar to \" +  \"\\'\" + index2word[j] + \"\\'\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "var = vocab.to()\n",
    "voc_dict = var.vocab.get_stoi()\n",
    "vocab_list = [x for x in voc_dict.keys()]\n",
    "df = pd.DataFrame(vocab_list).to_csv('../website/vocab.tsv', header=False, index=False, sep=\"\\t\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [],
   "source": [
    "track = []\n",
    "for word in range(len(vocab_list)):\n",
    "    ind = torch.tensor(word, dtype=torch.int).cpu()\n",
    "    emb = best_model.embeddings(ind)\n",
    "    track.append(emb.tolist())\n",
    "df2 = pd.DataFrame(track).to_csv('../website/embedd.tsv', header=False, index=False, sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "conjugations = ['am', 'are', 'is', 'has', 'were', 'was', 'being', 'been','be', 'have', 'had', 'having']\n",
    "\n",
    "conj_vocab = {}\n",
    "for i in range(len(conjugations)):\n",
    "    conj_vocab[vocab[conjugations[i]]] = i\n",
    "\n",
    "def create_dataset_between(\n",
    "    text, vocab, context_size=2,\n",
    "):\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    n_text = len(text)\n",
    "\n",
    "    # Transform the text as a list of integers.\n",
    "    txt = [vocab[w] for w in text]\n",
    "\n",
    "    for i in range(1, n_text - context_size - 1):\n",
    "\n",
    "        # true label = 'is the next word a known word (i.e. not '<unk>' token)?'\n",
    "        if txt[i] == 0 or index2word[txt[i]] not in conjugations:\n",
    "            continue\n",
    "\n",
    "        t = conj_vocab[txt[i]]\n",
    "\n",
    "        # Context before\n",
    "        c = [txt[i - 1]] + [txt[i + 1]]\n",
    "\n",
    "        targets.append(t)\n",
    "        # Normally we should use word embedding, and not hot encoding, but we\n",
    "        # skip that part for this exercise\n",
    "        contexts.append(torch.tensor(c))\n",
    "\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    return TensorDataset(contexts, targets)\n",
    "\n",
    "data_train_between = create_dataset_between(list_words_train, vocab)\n",
    "data_val_between = create_dataset_between(list_words_val, vocab)\n",
    "data_test_between = create_dataset_between(list_words_test, vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [],
   "source": [
    "train_loader_between = DataLoader(data_train_between, batch_size=64, shuffle=False)\n",
    "val_loader_between = DataLoader(data_val_between, batch_size=64, shuffle=False)\n",
    "test_loader_between = DataLoader(data_test_between, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [],
   "source": [
    "class MLP1(nn.Module):\n",
    "  def __init__(self, embedding_dim, context_size, num_classes, hidden_size):\n",
    "    super(MLP1, self).__init__()\n",
    "    #self.embeddings = nn.Embedding.from_pretrained(best_model.embeddings, freeze=True)\n",
    "    self.embeddings = best_model.embeddings\n",
    "    self.linear = nn.Linear(context_size * embedding_dim, hidden_size)\n",
    "    self.output = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    embeds = self.embeddings(x)\n",
    "    embeds = torch.flatten(embeds, 1)\n",
    "    out = F.relu(self.linear(embeds))\n",
    "    out = self.output(out)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, num_classes, hidden_size, num_layers):\n",
    "        super(RNN1, self).__init__()\n",
    "        #self.embeddings = nn.Embedding.from_pretrained(best_model.embeddings, freeze=True)\n",
    "        self.embeddings = best_model.embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size=hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.output = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embeddings(x)\n",
    "        out, (h_n, c_n) = self.lstm(embeds)\n",
    "        out = self.output(h_n[-1])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "  def __init__(self, embedding_dim, context_size, num_classes, hidden_size):\n",
    "    super(MLP2, self).__init__()\n",
    "    #self.embeddings = nn.Embedding.from_pretrained(best_model.embeddings, freeze=True)\n",
    "    self.embeddings = best_model.embeddings\n",
    "    self.linear = nn.Linear(context_size * embedding_dim, hidden_size)\n",
    "    self.output = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    embeds = self.embeddings(x)\n",
    "    embeds = torch.flatten(embeds, 1)\n",
    "    out = F.relu(self.linear(embeds))\n",
    "    out = self.output(out)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, num_classes, hidden_size, num_layers):\n",
    "        super(RNN2, self).__init__()\n",
    "        #self.embeddings = nn.Embedding.from_pretrained(best_model.embeddings, freeze=True)\n",
    "        self.embeddings = best_model.embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size=hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.output = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embeddings(x)\n",
    "        out, (h_n, c_n) = self.lstm(embeds)\n",
    "        out = self.output(h_n[-1])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 16\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 20  # Epochs\n",
    "BATCH_SIZE = 64  # Batch size  // Not used yet\n",
    "\n",
    "#Optimizer parameters\n",
    "LR = 1e-3  # Learning Rate\n",
    "BETAS = (0.9, 0.999)  # ADAM Momentum and RSMProp Betas\n",
    "EPSILON = 1e-8  # ADAM Vanishing and Exploding Gradients\n",
    "LAMBDA = 1e-8  # L2 Regularization\n",
    "\n",
    "SHALLOW_HIDDEN_SIZE = 32\n",
    "DEEP_HIDDEN_SIZE = 64\n",
    "\n",
    "NUMBER_OF_LAYERS = 2\n",
    "\n",
    "models, model_names, losses_train, time_mlp, time_rnn = [], [], [], [], []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:58:39.484096  |  Epoch 1  |  Training loss 2.46497\n",
      "16:58:40.461222  |  Epoch 2  |  Training loss 2.38932\n",
      "16:58:41.437378  |  Epoch 3  |  Training loss 2.29884\n",
      "16:58:42.421572  |  Epoch 4  |  Training loss 2.21288\n",
      "16:58:43.400904  |  Epoch 5  |  Training loss 2.13572\n",
      "16:58:44.377759  |  Epoch 6  |  Training loss 2.06914\n",
      "16:58:45.375729  |  Epoch 7  |  Training loss 2.01243\n",
      "16:58:46.415136  |  Epoch 8  |  Training loss 1.96353\n",
      "16:58:47.390805  |  Epoch 9  |  Training loss 1.92082\n",
      "16:58:48.365745  |  Epoch 10  |  Training loss 1.88338\n",
      "16:58:49.345277  |  Epoch 11  |  Training loss 1.84999\n",
      "16:58:50.311323  |  Epoch 12  |  Training loss 1.82015\n",
      "16:58:51.288008  |  Epoch 13  |  Training loss 1.79366\n",
      "16:58:52.254573  |  Epoch 14  |  Training loss 1.76970\n",
      "16:58:53.224603  |  Epoch 15  |  Training loss 1.74798\n",
      "16:58:54.195328  |  Epoch 16  |  Training loss 1.72831\n",
      "16:58:55.149470  |  Epoch 17  |  Training loss 1.71022\n",
      "16:58:56.078621  |  Epoch 18  |  Training loss 1.69346\n",
      "16:58:57.800564  |  Epoch 19  |  Training loss 1.67803\n",
      "16:58:59.627280  |  Epoch 20  |  Training loss 1.66370\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model1.parameters(), lr=LR, betas=BETAS, eps=EPSILON, weight_decay=LAMBDA)\n",
    "\n",
    "model1 = MLP1(EMBEDDING_DIM, CONTEXT_SIZE, len(conjugations), DEEP_HIDDEN_SIZE)\n",
    "star_time = time.time()\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model1,\n",
    "    loss_function,\n",
    "    train_loader_between\n",
    ")\n",
    "time_mlp.append(time.time() - star_time)\n",
    "models.append(model1)\n",
    "model_names.append(\"Deep MLP\")\n",
    "losses_train.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:59:03.583149  |  Epoch 1  |  Training loss 2.47366\n",
      "16:59:07.532782  |  Epoch 2  |  Training loss 2.47334\n",
      "16:59:10.525913  |  Epoch 3  |  Training loss 2.47281\n",
      "16:59:14.220926  |  Epoch 4  |  Training loss 2.47194\n",
      "16:59:17.173949  |  Epoch 5  |  Training loss 2.47057\n",
      "16:59:20.106495  |  Epoch 6  |  Training loss 2.46853\n",
      "16:59:23.067141  |  Epoch 7  |  Training loss 2.46590\n",
      "16:59:26.104211  |  Epoch 8  |  Training loss 2.46300\n",
      "16:59:29.165413  |  Epoch 9  |  Training loss 2.45995\n",
      "16:59:31.843816  |  Epoch 10  |  Training loss 2.45678\n",
      "16:59:34.481997  |  Epoch 11  |  Training loss 2.45352\n",
      "16:59:37.159384  |  Epoch 12  |  Training loss 2.45013\n",
      "16:59:39.798970  |  Epoch 13  |  Training loss 2.44693\n",
      "16:59:42.509227  |  Epoch 14  |  Training loss 2.44388\n",
      "16:59:45.173609  |  Epoch 15  |  Training loss 2.44102\n",
      "16:59:47.830130  |  Epoch 16  |  Training loss 2.43851\n",
      "16:59:50.418374  |  Epoch 17  |  Training loss 2.43628\n",
      "16:59:53.027001  |  Epoch 18  |  Training loss 2.43425\n",
      "16:59:55.674141  |  Epoch 19  |  Training loss 2.43237\n",
      "16:59:58.286048  |  Epoch 20  |  Training loss 2.43061\n"
     ]
    }
   ],
   "source": [
    "model2 = RNN1(EMBEDDING_DIM, len(conjugations), DEEP_HIDDEN_SIZE, NUMBER_OF_LAYERS)\n",
    "star_time = time.time()\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model2,\n",
    "    loss_function,\n",
    "    train_loader_between\n",
    ")\n",
    "time_rnn.append(time.time() - star_time)\n",
    "models.append(model2)\n",
    "model_names.append(\"Deep RNN\")\n",
    "losses_train.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:59:59.210145  |  Epoch 1  |  Training loss 2.48867\n",
      "17:00:00.145292  |  Epoch 2  |  Training loss 2.32599\n",
      "17:00:01.086596  |  Epoch 3  |  Training loss 2.22412\n",
      "17:00:02.030650  |  Epoch 4  |  Training loss 2.14368\n",
      "17:00:03.328421  |  Epoch 5  |  Training loss 2.07674\n",
      "17:00:04.980001  |  Epoch 6  |  Training loss 2.01869\n",
      "17:00:06.100692  |  Epoch 7  |  Training loss 1.96801\n",
      "17:00:07.228250  |  Epoch 8  |  Training loss 1.92371\n",
      "17:00:08.374875  |  Epoch 9  |  Training loss 1.88423\n",
      "17:00:09.661965  |  Epoch 10  |  Training loss 1.84839\n",
      "17:00:10.799706  |  Epoch 11  |  Training loss 1.81593\n",
      "17:00:12.475288  |  Epoch 12  |  Training loss 1.78693\n",
      "17:00:14.383766  |  Epoch 13  |  Training loss 1.76073\n",
      "17:00:16.049671  |  Epoch 14  |  Training loss 1.73655\n",
      "17:00:17.268803  |  Epoch 15  |  Training loss 1.71434\n",
      "17:00:18.783436  |  Epoch 16  |  Training loss 1.69393\n",
      "17:00:20.146718  |  Epoch 17  |  Training loss 1.67499\n",
      "17:00:21.822634  |  Epoch 18  |  Training loss 1.65712\n",
      "17:00:23.320244  |  Epoch 19  |  Training loss 1.64035\n",
      "17:00:24.831557  |  Epoch 20  |  Training loss 1.62490\n"
     ]
    }
   ],
   "source": [
    "model3 = MLP2(EMBEDDING_DIM, CONTEXT_SIZE, len(conjugations), SHALLOW_HIDDEN_SIZE)\n",
    "star_time = time.time()\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model3,\n",
    "    loss_function,\n",
    "    train_loader_between\n",
    ")\n",
    "time_mlp.append(time.time() - star_time)\n",
    "models.append(model3)\n",
    "model_names.append(\"SHALLOW MLP\")\n",
    "losses_train.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:00:28.006544  |  Epoch 1  |  Training loss 2.48189\n",
      "17:00:31.104738  |  Epoch 2  |  Training loss 2.48131\n",
      "17:00:34.019227  |  Epoch 3  |  Training loss 2.48035\n",
      "17:00:37.014544  |  Epoch 4  |  Training loss 2.47881\n",
      "17:00:40.044552  |  Epoch 5  |  Training loss 2.47656\n",
      "17:00:43.018292  |  Epoch 6  |  Training loss 2.47376\n",
      "17:00:45.902249  |  Epoch 7  |  Training loss 2.47088\n",
      "17:00:48.743609  |  Epoch 8  |  Training loss 2.46821\n",
      "17:00:51.122821  |  Epoch 9  |  Training loss 2.46556\n",
      "17:00:53.514748  |  Epoch 10  |  Training loss 2.46265\n",
      "17:00:55.955674  |  Epoch 11  |  Training loss 2.46004\n",
      "17:00:58.307292  |  Epoch 12  |  Training loss 2.45741\n",
      "17:01:00.481665  |  Epoch 13  |  Training loss 2.45480\n",
      "17:01:02.629987  |  Epoch 14  |  Training loss 2.45262\n",
      "17:01:04.827612  |  Epoch 15  |  Training loss 2.45064\n",
      "17:01:07.020696  |  Epoch 16  |  Training loss 2.44884\n",
      "17:01:09.471835  |  Epoch 17  |  Training loss 2.44717\n",
      "17:01:12.566932  |  Epoch 18  |  Training loss 2.44557\n",
      "17:01:15.440328  |  Epoch 19  |  Training loss 2.44406\n",
      "17:01:18.396826  |  Epoch 20  |  Training loss 2.44263\n"
     ]
    }
   ],
   "source": [
    "model4 = RNN2(EMBEDDING_DIM, len(conjugations), SHALLOW_HIDDEN_SIZE, NUMBER_OF_LAYERS)\n",
    "star_time = time.time()\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model4,\n",
    "    loss_function,\n",
    "    train_loader_between\n",
    ")\n",
    "time_rnn.append(time.time() - star_time)\n",
    "models.append(model4)\n",
    "model_names.append(\"SHALLOW RNN\")\n",
    "losses_train.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, e in zip(losses, model_names):\n",
    "    plt.plot(i, label=e)\n",
    "    plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is: SHALLOW MLP\n"
     ]
    }
   ],
   "source": [
    "best_model = find_best_model(val_loader_between)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of the best model is 30.68%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy of the best model is \" + str(round(compute_accuracy(best_model, test_loader_between) * 100, 2)) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avrage time training MLP: 23.82 seconds vs average time training RNN 56.1 seconds\n"
     ]
    }
   ],
   "source": [
    "avg_time_mlp = 0\n",
    "avg_time_rnn = 0\n",
    "for i in range(len(time_mlp)):\n",
    "    avg_time_mlp += time_mlp[i]\n",
    "    avg_time_rnn += time_rnn[i]\n",
    "\n",
    "print(\"Avrage time training MLP:\", round(avg_time_mlp / len(time_mlp), 2), \"seconds vs average time training RNN\", round(avg_time_rnn / len(time_rnn), 2),\"seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, num_classes, hidden_size, num_layers):\n",
    "        super(RNN1, self).__init__()\n",
    "        #self.embeddings = nn.Embedding.from_pretrained(best_model.embeddings, freeze=True)\n",
    "        self.embeddings = best_model.embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size=hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.output = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embeddings(x)\n",
    "        out, (h_n, c_n) = self.lstm(embeds)\n",
    "        out = self.output(h_n[-1])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, num_classes, hidden_size, num_layers):\n",
    "        super(RNN2, self).__init__()\n",
    "        #self.embeddings = nn.Embedding.from_pretrained(best_model.embeddings, freeze=True)\n",
    "        self.embeddings = best_model.embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size=hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.output = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embeddings(x)\n",
    "        out, (h_n, c_n) = self.lstm(embeds)\n",
    "        out = self.output(h_n[-1])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 16\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 5  # Epochs\n",
    "BATCH_SIZE = 64  # Batch size  // Not used yet\n",
    "\n",
    "#Optimizer parameters\n",
    "LR = 1e-2  # Learning Rate\n",
    "BETAS = (0.9, 0.999)  # ADAM Momentum and RSMProp Betas\n",
    "EPSILON = 1e-8  # ADAM Vanishing and Exploding Gradients\n",
    "LAMBDA = 1e-16  # L2 Regularization\n",
    "\n",
    "SHALLOW_HIDDEN_SIZE = 32\n",
    "DEEP_HIDDEN_SIZE = 64\n",
    "\n",
    "NUMBER_OF_LAYERS = 1\n",
    "\n",
    "models, model_names, losses_train = [], [], []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:25:08.350093  |  Epoch 1  |  Training loss 6.88710\n",
      "17:25:58.352424  |  Epoch 2  |  Training loss 6.81835\n",
      "17:26:40.002889  |  Epoch 3  |  Training loss 6.79641\n",
      "17:27:23.544905  |  Epoch 4  |  Training loss 6.78519\n",
      "17:28:13.473075  |  Epoch 5  |  Training loss 6.77737\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model1.parameters(), lr=LR, betas=BETAS, eps=EPSILON, weight_decay=LAMBDA)\n",
    "\n",
    "model1 = RNN1(EMBEDDING_DIM, vocab_size, DEEP_HIDDEN_SIZE, NUMBER_OF_LAYERS)\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model1,\n",
    "    loss_function,\n",
    "    train_loader\n",
    ")\n",
    "\n",
    "models.append(model1)\n",
    "model_names.append(\"DEEP RNN\")\n",
    "losses_train.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:28:52.061770  |  Epoch 1  |  Training loss 6.90548\n",
      "17:29:28.664914  |  Epoch 2  |  Training loss 6.87412\n",
      "17:30:05.713216  |  Epoch 3  |  Training loss 6.86158\n",
      "17:30:43.103845  |  Epoch 4  |  Training loss 6.85450\n",
      "17:31:22.635236  |  Epoch 5  |  Training loss 6.84930\n"
     ]
    }
   ],
   "source": [
    "model2 = RNN2(EMBEDDING_DIM, vocab_size, SHALLOW_HIDDEN_SIZE, NUMBER_OF_LAYERS)\n",
    "loss = train(\n",
    "    EPOCHS,\n",
    "    optimizer,\n",
    "    model2,\n",
    "    loss_function,\n",
    "    train_loader\n",
    ")\n",
    "\n",
    "models.append(model2)\n",
    "model_names.append(\"SHALLOW RNN\")\n",
    "losses_train.append(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is: DEEP RNN\n"
     ]
    }
   ],
   "source": [
    "best_model = find_best_model(val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of the best model is 0.99%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy of the best model is \" + str(round(compute_accuracy(best_model, test_loader) * 100, 2)) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "outputs": [],
   "source": [
    "def getRandomText(text,length, beam_size):\n",
    "    txt = text.lower().split()\n",
    "     # Transform the text as a list of integers.\n",
    "    text_as_indices = [vocab[w] for w in txt]\n",
    "\n",
    "    beams = [(text_as_indices, -100.0)]\n",
    "    for _ in range(length):\n",
    "        new_beams = []\n",
    "        for beam in beams:\n",
    "            model_output = torch.log_softmax(best_model(torch.tensor(beam[0])), dim=0)  # Log gives negative values [0, 1)\n",
    "\n",
    "            top_k = torch.topk(model_output, beam_size, dim=0)\n",
    "            values, indices = top_k.values, top_k.indices\n",
    "            for i in range(len(values)):\n",
    "                new_beam = beam[0].copy()\n",
    "                word_as_indices = indices[i].item()\n",
    "                prob = values[i].item()\n",
    "\n",
    "                if word_as_indices == 0 or word_as_indices == new_beam[-1]:\n",
    "                    continue\n",
    "\n",
    "                new_beam.append(word_as_indices)\n",
    "                new_beams.append((new_beam, prob))\n",
    "\n",
    "        new_beams = sorted(new_beams, key=lambda x : x[1], reverse=True)\n",
    "        beams = new_beams[:3]\n",
    "\n",
    "    return ' '.join([index2word[w] for w in beams[0][0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "outputs": [
    {
     "data": {
      "text/plain": "'sir arrived at <unk> with train and was happy waiting am tomorrow anything waiting am'"
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRandomText(\"Sir arrived at noon with train and was happy\", 6, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [
    {
     "data": {
      "text/plain": "'a dream understand anger'"
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRandomText(\"A dream\", 2, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "outputs": [
    {
     "data": {
      "text/plain": "'i have a dream a world where cannot woman commander world . darkness run wall reason . twenty ring . darkness run wall reason . darkness am'"
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRandomText(\"I have a dream a world where \", 20, 7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "outputs": [
    {
     "data": {
      "text/plain": "'i have a dream that one day on the red <unk> of <unk> the <unk> of former <unk> and the <unk> of former <unk> <unk> will be able to sit down together at the table of <unk> tried drink anything tried given to commander world quite saying troops together waiting officer reason . darkness run wall reason . darkness run wall reason . darkness run wall am'"
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRandomText(\"I have a dream that one day on the red hills of Georgia, the sons of former slaves and the sons of former slave owners will be able to sit down together at the table of brotherhood.\", 30, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}